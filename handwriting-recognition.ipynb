{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras import optimizers\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "nr_classes = 10\n",
    "nr_iterations = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 6s 1us/step\n",
      "11501568/11490434 [==============================] - 6s 1us/step\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(y_train, nr_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nr_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(784,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                2570      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 203,530\n",
      "Trainable params: 203,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/keras/models.py:939: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 11s 181us/step - loss: 0.4398 - acc: 0.8698 - val_loss: 0.1908 - val_acc: 0.9432\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 11s 176us/step - loss: 0.2205 - acc: 0.9368 - val_loss: 0.1393 - val_acc: 0.9591\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 11s 186us/step - loss: 0.1732 - acc: 0.9487 - val_loss: 0.1125 - val_acc: 0.9652\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 11s 188us/step - loss: 0.1474 - acc: 0.9566 - val_loss: 0.0972 - val_acc: 0.9701\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 11s 188us/step - loss: 0.1316 - acc: 0.9612 - val_loss: 0.0953 - val_acc: 0.9711\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 11s 189us/step - loss: 0.1169 - acc: 0.9648 - val_loss: 0.0847 - val_acc: 0.9741\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 11s 186us/step - loss: 0.1085 - acc: 0.9679 - val_loss: 0.0799 - val_acc: 0.9754\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 11s 191us/step - loss: 0.1008 - acc: 0.9689 - val_loss: 0.0756 - val_acc: 0.9782\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 11s 188us/step - loss: 0.0949 - acc: 0.9710 - val_loss: 0.0734 - val_acc: 0.9774\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 11s 189us/step - loss: 0.0877 - acc: 0.9732 - val_loss: 0.0740 - val_acc: 0.9767\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 11s 188us/step - loss: 0.0836 - acc: 0.9746 - val_loss: 0.0704 - val_acc: 0.9791\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 11s 187us/step - loss: 0.0811 - acc: 0.9742 - val_loss: 0.0661 - val_acc: 0.9798\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 11s 187us/step - loss: 0.0743 - acc: 0.9765 - val_loss: 0.0680 - val_acc: 0.9790\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 11s 190us/step - loss: 0.0730 - acc: 0.9770 - val_loss: 0.0642 - val_acc: 0.9804\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 11s 189us/step - loss: 0.0688 - acc: 0.9779 - val_loss: 0.0663 - val_acc: 0.9795\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 11s 189us/step - loss: 0.0665 - acc: 0.9786 - val_loss: 0.0683 - val_acc: 0.9801\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 11s 189us/step - loss: 0.0630 - acc: 0.9800 - val_loss: 0.0686 - val_acc: 0.9784\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 11s 191us/step - loss: 0.0630 - acc: 0.9792 - val_loss: 0.0649 - val_acc: 0.9802\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 12s 192us/step - loss: 0.0616 - acc: 0.9797 - val_loss: 0.0674 - val_acc: 0.9806\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 11s 190us/step - loss: 0.0591 - acc: 0.9805 - val_loss: 0.0658 - val_acc: 0.9811\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size = batch_size, nb_epoch = nr_iterations,\n",
    "                    verbose = 1, validation_data = (X_test, Y_test))\n",
    "score = model.evaluate(X_test, Y_test, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "60000/60000 [==============================] - 11s 184us/step - loss: 0.0570 - acc: 0.9815 - val_loss: 0.0704 - val_acc: 0.9819\n",
      "Epoch 2/40\n",
      "60000/60000 [==============================] - 11s 184us/step - loss: 0.0561 - acc: 0.9817 - val_loss: 0.0662 - val_acc: 0.9816\n",
      "Epoch 3/40\n",
      "60000/60000 [==============================] - 11s 188us/step - loss: 0.0555 - acc: 0.9817 - val_loss: 0.0647 - val_acc: 0.9804\n",
      "Epoch 4/40\n",
      "60000/60000 [==============================] - 11s 189us/step - loss: 0.0529 - acc: 0.9828 - val_loss: 0.0675 - val_acc: 0.9810\n",
      "Epoch 5/40\n",
      "60000/60000 [==============================] - 11s 188us/step - loss: 0.0512 - acc: 0.9826 - val_loss: 0.0620 - val_acc: 0.9821\n",
      "Epoch 6/40\n",
      "60000/60000 [==============================] - 11s 187us/step - loss: 0.0471 - acc: 0.9846 - val_loss: 0.0653 - val_acc: 0.9808\n",
      "Epoch 7/40\n",
      "60000/60000 [==============================] - 11s 189us/step - loss: 0.0493 - acc: 0.9836 - val_loss: 0.0684 - val_acc: 0.9820\n",
      "Epoch 8/40\n",
      "60000/60000 [==============================] - 12s 192us/step - loss: 0.0506 - acc: 0.9831 - val_loss: 0.0650 - val_acc: 0.9822\n",
      "Epoch 9/40\n",
      "60000/60000 [==============================] - 14s 239us/step - loss: 0.0473 - acc: 0.9841 - val_loss: 0.0663 - val_acc: 0.9807\n",
      "Epoch 10/40\n",
      "60000/60000 [==============================] - 12s 192us/step - loss: 0.0461 - acc: 0.9845 - val_loss: 0.0675 - val_acc: 0.9817\n",
      "Epoch 11/40\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 0.0447 - acc: 0.9850 - val_loss: 0.0662 - val_acc: 0.9821\n",
      "Epoch 12/40\n",
      "60000/60000 [==============================] - 12s 205us/step - loss: 0.0424 - acc: 0.9857 - val_loss: 0.0648 - val_acc: 0.9817\n",
      "Epoch 13/40\n",
      "60000/60000 [==============================] - 12s 207us/step - loss: 0.0416 - acc: 0.9857 - val_loss: 0.0655 - val_acc: 0.9826\n",
      "Epoch 14/40\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 0.0417 - acc: 0.9856 - val_loss: 0.0643 - val_acc: 0.9824\n",
      "Epoch 15/40\n",
      "60000/60000 [==============================] - 11s 189us/step - loss: 0.0403 - acc: 0.9862 - val_loss: 0.0652 - val_acc: 0.9828\n",
      "Epoch 16/40\n",
      "60000/60000 [==============================] - 11s 191us/step - loss: 0.0429 - acc: 0.9852 - val_loss: 0.0700 - val_acc: 0.9813\n",
      "Epoch 17/40\n",
      "60000/60000 [==============================] - 13s 213us/step - loss: 0.0398 - acc: 0.9865 - val_loss: 0.0676 - val_acc: 0.9823\n",
      "Epoch 18/40\n",
      "60000/60000 [==============================] - 11s 187us/step - loss: 0.0400 - acc: 0.9860 - val_loss: 0.0711 - val_acc: 0.9814\n",
      "Epoch 19/40\n",
      "60000/60000 [==============================] - 13s 215us/step - loss: 0.0410 - acc: 0.9862 - val_loss: 0.0661 - val_acc: 0.9813\n",
      "Epoch 20/40\n",
      "60000/60000 [==============================] - 13s 216us/step - loss: 0.0377 - acc: 0.9871 - val_loss: 0.0678 - val_acc: 0.9825\n",
      "Epoch 21/40\n",
      "60000/60000 [==============================] - 13s 217us/step - loss: 0.0397 - acc: 0.9864 - val_loss: 0.0685 - val_acc: 0.9811\n",
      "Epoch 22/40\n",
      "60000/60000 [==============================] - 12s 196us/step - loss: 0.0379 - acc: 0.9869 - val_loss: 0.0721 - val_acc: 0.9809\n",
      "Epoch 23/40\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 0.0369 - acc: 0.9868 - val_loss: 0.0711 - val_acc: 0.9818\n",
      "Epoch 24/40\n",
      "60000/60000 [==============================] - 14s 229us/step - loss: 0.0346 - acc: 0.9879 - val_loss: 0.0748 - val_acc: 0.9803\n",
      "Epoch 25/40\n",
      "60000/60000 [==============================] - 13s 219us/step - loss: 0.0344 - acc: 0.9878 - val_loss: 0.0715 - val_acc: 0.9819\n",
      "Epoch 26/40\n",
      "60000/60000 [==============================] - 12s 196us/step - loss: 0.0352 - acc: 0.9878 - val_loss: 0.0734 - val_acc: 0.9820\n",
      "Epoch 27/40\n",
      "60000/60000 [==============================] - 12s 193us/step - loss: 0.0354 - acc: 0.9883 - val_loss: 0.0682 - val_acc: 0.9826\n",
      "Epoch 28/40\n",
      "60000/60000 [==============================] - 12s 197us/step - loss: 0.0335 - acc: 0.9887 - val_loss: 0.0719 - val_acc: 0.9817\n",
      "Epoch 29/40\n",
      "60000/60000 [==============================] - 12s 200us/step - loss: 0.0344 - acc: 0.9886 - val_loss: 0.0724 - val_acc: 0.9810\n",
      "Epoch 30/40\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 0.0329 - acc: 0.9888 - val_loss: 0.0738 - val_acc: 0.9819\n",
      "Epoch 31/40\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 0.0332 - acc: 0.9889 - val_loss: 0.0761 - val_acc: 0.9810\n",
      "Epoch 32/40\n",
      "60000/60000 [==============================] - 12s 199us/step - loss: 0.0335 - acc: 0.9886 - val_loss: 0.0776 - val_acc: 0.9821\n",
      "Epoch 33/40\n",
      "60000/60000 [==============================] - 13s 220us/step - loss: 0.0329 - acc: 0.9884 - val_loss: 0.0770 - val_acc: 0.9822\n",
      "Epoch 34/40\n",
      "60000/60000 [==============================] - 14s 236us/step - loss: 0.0327 - acc: 0.9886 - val_loss: 0.0764 - val_acc: 0.9810\n",
      "Epoch 35/40\n",
      "60000/60000 [==============================] - 14s 229us/step - loss: 0.0329 - acc: 0.9879 - val_loss: 0.0769 - val_acc: 0.9816\n",
      "Epoch 36/40\n",
      "60000/60000 [==============================] - 12s 196us/step - loss: 0.0318 - acc: 0.9886 - val_loss: 0.0734 - val_acc: 0.9830\n",
      "Epoch 37/40\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 0.0304 - acc: 0.9899 - val_loss: 0.0767 - val_acc: 0.9816\n",
      "Epoch 38/40\n",
      "60000/60000 [==============================] - 12s 196us/step - loss: 0.0323 - acc: 0.9888 - val_loss: 0.0756 - val_acc: 0.9825\n",
      "Epoch 39/40\n",
      "60000/60000 [==============================] - 12s 199us/step - loss: 0.0295 - acc: 0.9900 - val_loss: 0.0793 - val_acc: 0.9823\n",
      "Epoch 40/40\n",
      "60000/60000 [==============================] - 12s 208us/step - loss: 0.0304 - acc: 0.9895 - val_loss: 0.0723 - val_acc: 0.9820\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size = batch_size, nb_epoch = nr_iterations,\n",
    "                    verbose = 1, validation_data = (X_test, Y_test))\n",
    "score = model.evaluate(X_test, Y_test, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "60000/60000 [==============================] - 14s 227us/step - loss: 0.4028 - acc: 0.8802 - val_loss: 0.1796 - val_acc: 0.9477\n",
      "Epoch 2/40\n",
      "60000/60000 [==============================] - 14s 236us/step - loss: 0.1992 - acc: 0.9422 - val_loss: 0.1254 - val_acc: 0.9620\n",
      "Epoch 3/40\n",
      "60000/60000 [==============================] - 14s 238us/step - loss: 0.1551 - acc: 0.9544 - val_loss: 0.1041 - val_acc: 0.9691\n",
      "Epoch 4/40\n",
      "60000/60000 [==============================] - 15s 246us/step - loss: 0.1321 - acc: 0.9602 - val_loss: 0.0898 - val_acc: 0.9728\n",
      "Epoch 5/40\n",
      "60000/60000 [==============================] - 14s 240us/step - loss: 0.1126 - acc: 0.9662 - val_loss: 0.0812 - val_acc: 0.9749\n",
      "Epoch 6/40\n",
      "60000/60000 [==============================] - 14s 237us/step - loss: 0.1005 - acc: 0.9698 - val_loss: 0.0769 - val_acc: 0.9772\n",
      "Epoch 7/40\n",
      "60000/60000 [==============================] - 14s 238us/step - loss: 0.0925 - acc: 0.9717 - val_loss: 0.0759 - val_acc: 0.9781\n",
      "Epoch 8/40\n",
      "60000/60000 [==============================] - 14s 236us/step - loss: 0.0860 - acc: 0.9738 - val_loss: 0.0687 - val_acc: 0.9786\n",
      "Epoch 9/40\n",
      "60000/60000 [==============================] - 16s 267us/step - loss: 0.0780 - acc: 0.9761 - val_loss: 0.0688 - val_acc: 0.9778\n",
      "Epoch 10/40\n",
      "60000/60000 [==============================] - 17s 282us/step - loss: 0.0717 - acc: 0.9771 - val_loss: 0.0671 - val_acc: 0.9784\n",
      "Epoch 11/40\n",
      "60000/60000 [==============================] - 16s 275us/step - loss: 0.0694 - acc: 0.9778 - val_loss: 0.0684 - val_acc: 0.9789\n",
      "Epoch 12/40\n",
      "60000/60000 [==============================] - 15s 256us/step - loss: 0.0637 - acc: 0.9799 - val_loss: 0.0657 - val_acc: 0.9798\n",
      "Epoch 13/40\n",
      "60000/60000 [==============================] - 15s 250us/step - loss: 0.0633 - acc: 0.9797 - val_loss: 0.0647 - val_acc: 0.9805\n",
      "Epoch 14/40\n",
      "60000/60000 [==============================] - 16s 272us/step - loss: 0.0590 - acc: 0.9811 - val_loss: 0.0645 - val_acc: 0.9807\n",
      "Epoch 15/40\n",
      "60000/60000 [==============================] - 16s 270us/step - loss: 0.0553 - acc: 0.9824 - val_loss: 0.0665 - val_acc: 0.9798\n",
      "Epoch 16/40\n",
      "60000/60000 [==============================] - 16s 271us/step - loss: 0.0534 - acc: 0.9826 - val_loss: 0.0621 - val_acc: 0.9819\n",
      "Epoch 17/40\n",
      "60000/60000 [==============================] - 15s 255us/step - loss: 0.0490 - acc: 0.9839 - val_loss: 0.0601 - val_acc: 0.9818\n",
      "Epoch 18/40\n",
      "60000/60000 [==============================] - 16s 261us/step - loss: 0.0492 - acc: 0.9832 - val_loss: 0.0649 - val_acc: 0.9822\n",
      "Epoch 19/40\n",
      "60000/60000 [==============================] - 16s 261us/step - loss: 0.0472 - acc: 0.9843 - val_loss: 0.0674 - val_acc: 0.9805\n",
      "Epoch 20/40\n",
      "60000/60000 [==============================] - 14s 241us/step - loss: 0.0447 - acc: 0.9852 - val_loss: 0.0643 - val_acc: 0.9826\n",
      "Epoch 21/40\n",
      "60000/60000 [==============================] - 15s 243us/step - loss: 0.0418 - acc: 0.9864 - val_loss: 0.0633 - val_acc: 0.9828\n",
      "Epoch 22/40\n",
      "60000/60000 [==============================] - 16s 265us/step - loss: 0.0439 - acc: 0.9854 - val_loss: 0.0612 - val_acc: 0.9824\n",
      "Epoch 23/40\n",
      "60000/60000 [==============================] - 15s 256us/step - loss: 0.0416 - acc: 0.9864 - val_loss: 0.0644 - val_acc: 0.9832\n",
      "Epoch 24/40\n",
      "60000/60000 [==============================] - 14s 240us/step - loss: 0.0402 - acc: 0.9863 - val_loss: 0.0636 - val_acc: 0.9821\n",
      "Epoch 25/40\n",
      "60000/60000 [==============================] - 15s 258us/step - loss: 0.0383 - acc: 0.9873 - val_loss: 0.0663 - val_acc: 0.9828\n",
      "Epoch 26/40\n",
      "60000/60000 [==============================] - 15s 245us/step - loss: 0.0371 - acc: 0.9874 - val_loss: 0.0666 - val_acc: 0.9826\n",
      "Epoch 27/40\n",
      "60000/60000 [==============================] - 14s 240us/step - loss: 0.0372 - acc: 0.9872 - val_loss: 0.0671 - val_acc: 0.9822\n",
      "Epoch 28/40\n",
      "60000/60000 [==============================] - 15s 243us/step - loss: 0.0352 - acc: 0.9879 - val_loss: 0.0654 - val_acc: 0.9826\n",
      "Epoch 29/40\n",
      "60000/60000 [==============================] - 16s 260us/step - loss: 0.0336 - acc: 0.9884 - val_loss: 0.0647 - val_acc: 0.9832\n",
      "Epoch 30/40\n",
      "60000/60000 [==============================] - 15s 257us/step - loss: 0.0345 - acc: 0.9886 - val_loss: 0.0684 - val_acc: 0.9827\n",
      "Epoch 31/40\n",
      "60000/60000 [==============================] - 16s 275us/step - loss: 0.0315 - acc: 0.9891 - val_loss: 0.0655 - val_acc: 0.9831\n",
      "Epoch 32/40\n",
      "60000/60000 [==============================] - 16s 275us/step - loss: 0.0327 - acc: 0.9887 - val_loss: 0.0702 - val_acc: 0.9827\n",
      "Epoch 33/40\n",
      "60000/60000 [==============================] - 16s 264us/step - loss: 0.0321 - acc: 0.9890 - val_loss: 0.0723 - val_acc: 0.9823\n",
      "Epoch 34/40\n",
      "60000/60000 [==============================] - 16s 271us/step - loss: 0.0301 - acc: 0.9901 - val_loss: 0.0663 - val_acc: 0.9837\n",
      "Epoch 35/40\n",
      "60000/60000 [==============================] - 15s 245us/step - loss: 0.0309 - acc: 0.9895 - val_loss: 0.0679 - val_acc: 0.9823\n",
      "Epoch 36/40\n",
      "60000/60000 [==============================] - 15s 250us/step - loss: 0.0305 - acc: 0.9894 - val_loss: 0.0714 - val_acc: 0.9824\n",
      "Epoch 37/40\n",
      "60000/60000 [==============================] - 15s 242us/step - loss: 0.0281 - acc: 0.9903 - val_loss: 0.0715 - val_acc: 0.9832\n",
      "Epoch 38/40\n",
      "60000/60000 [==============================] - 15s 245us/step - loss: 0.0320 - acc: 0.9890 - val_loss: 0.0708 - val_acc: 0.9826\n",
      "Epoch 39/40\n",
      "60000/60000 [==============================] - 15s 246us/step - loss: 0.0285 - acc: 0.9902 - val_loss: 0.0706 - val_acc: 0.9816\n",
      "Epoch 40/40\n",
      "60000/60000 [==============================] - 15s 247us/step - loss: 0.0270 - acc: 0.9905 - val_loss: 0.0725 - val_acc: 0.9835\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size = batch_size, nb_epoch = nr_iterations,\n",
    "                    verbose = 1, validation_data = (X_test, Y_test))\n",
    "score = model.evaluate(X_test, Y_test, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=0.01, clipvalue=0.5),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/40\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.0170 - acc: 0.9942 - val_loss: 0.0691 - val_acc: 0.9828\n",
      "Epoch 2/40\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.0165 - acc: 0.9948 - val_loss: 0.0691 - val_acc: 0.9827\n",
      "Epoch 3/40\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.0155 - acc: 0.9950 - val_loss: 0.0692 - val_acc: 0.9827\n",
      "Epoch 4/40\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.0168 - acc: 0.9943 - val_loss: 0.0692 - val_acc: 0.9828\n",
      "Epoch 5/40\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.0156 - acc: 0.9948 - val_loss: 0.0691 - val_acc: 0.9829\n",
      "Epoch 6/40\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.0165 - acc: 0.9945 - val_loss: 0.0692 - val_acc: 0.9828\n",
      "Epoch 7/40\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.0162 - acc: 0.9947 - val_loss: 0.0691 - val_acc: 0.9827\n",
      "Epoch 8/40\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.0156 - acc: 0.9946 - val_loss: 0.0693 - val_acc: 0.9827\n",
      "Epoch 9/40\n",
      "60000/60000 [==============================] - 9s 155us/step - loss: 0.0158 - acc: 0.9950 - val_loss: 0.0692 - val_acc: 0.9827\n",
      "Epoch 10/40\n",
      "60000/60000 [==============================] - 9s 153us/step - loss: 0.0159 - acc: 0.9947 - val_loss: 0.0693 - val_acc: 0.9827\n",
      "Epoch 11/40\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.0164 - acc: 0.9947 - val_loss: 0.0694 - val_acc: 0.9827\n",
      "Epoch 12/40\n",
      "60000/60000 [==============================] - 9s 155us/step - loss: 0.0154 - acc: 0.9947 - val_loss: 0.0693 - val_acc: 0.9827\n",
      "Epoch 13/40\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 0.0162 - acc: 0.9948 - val_loss: 0.0695 - val_acc: 0.9827\n",
      "Epoch 14/40\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 0.0153 - acc: 0.9950 - val_loss: 0.0694 - val_acc: 0.9829\n",
      "Epoch 15/40\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 0.0157 - acc: 0.9948 - val_loss: 0.0694 - val_acc: 0.9829\n",
      "Epoch 16/40\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.0169 - acc: 0.9943 - val_loss: 0.0694 - val_acc: 0.9829\n",
      "Epoch 17/40\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 0.0161 - acc: 0.9948 - val_loss: 0.0693 - val_acc: 0.9829\n",
      "Epoch 18/40\n",
      "60000/60000 [==============================] - 9s 153us/step - loss: 0.0154 - acc: 0.9948 - val_loss: 0.0691 - val_acc: 0.9829\n",
      "Epoch 19/40\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 0.0137 - acc: 0.9956 - val_loss: 0.0693 - val_acc: 0.9830\n",
      "Epoch 20/40\n",
      "60000/60000 [==============================] - 9s 152us/step - loss: 0.0155 - acc: 0.9947 - val_loss: 0.0693 - val_acc: 0.9829\n",
      "Epoch 21/40\n",
      "60000/60000 [==============================] - 9s 155us/step - loss: 0.0164 - acc: 0.9942 - val_loss: 0.0692 - val_acc: 0.9829\n",
      "Epoch 22/40\n",
      "60000/60000 [==============================] - 9s 153us/step - loss: 0.0156 - acc: 0.9949 - val_loss: 0.0693 - val_acc: 0.9829\n",
      "Epoch 23/40\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 0.0154 - acc: 0.9950 - val_loss: 0.0694 - val_acc: 0.9830\n",
      "Epoch 24/40\n",
      "60000/60000 [==============================] - 9s 153us/step - loss: 0.0156 - acc: 0.9951 - val_loss: 0.0695 - val_acc: 0.9831\n",
      "Epoch 25/40\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 0.0157 - acc: 0.9948 - val_loss: 0.0695 - val_acc: 0.9832\n",
      "Epoch 26/40\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.0150 - acc: 0.9950 - val_loss: 0.0695 - val_acc: 0.9829\n",
      "Epoch 27/40\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.0154 - acc: 0.9950 - val_loss: 0.0696 - val_acc: 0.9830\n",
      "Epoch 28/40\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 0.0161 - acc: 0.9950 - val_loss: 0.0695 - val_acc: 0.9829\n",
      "Epoch 29/40\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.0159 - acc: 0.9945 - val_loss: 0.0693 - val_acc: 0.9829\n",
      "Epoch 30/40\n",
      "60000/60000 [==============================] - 9s 155us/step - loss: 0.0151 - acc: 0.9953 - val_loss: 0.0694 - val_acc: 0.9829\n",
      "Epoch 31/40\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.0158 - acc: 0.9953 - val_loss: 0.0693 - val_acc: 0.9829\n",
      "Epoch 32/40\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 0.0154 - acc: 0.9950 - val_loss: 0.0694 - val_acc: 0.9829\n",
      "Epoch 33/40\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.0153 - acc: 0.9951 - val_loss: 0.0694 - val_acc: 0.9829\n",
      "Epoch 34/40\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.0160 - acc: 0.9948 - val_loss: 0.0691 - val_acc: 0.9829\n",
      "Epoch 35/40\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.0146 - acc: 0.9953 - val_loss: 0.0691 - val_acc: 0.9828\n",
      "Epoch 36/40\n",
      "60000/60000 [==============================] - 9s 155us/step - loss: 0.0149 - acc: 0.9950 - val_loss: 0.0691 - val_acc: 0.9828\n",
      "Epoch 37/40\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 0.0163 - acc: 0.9946 - val_loss: 0.0692 - val_acc: 0.9828\n",
      "Epoch 38/40\n",
      "60000/60000 [==============================] - 9s 155us/step - loss: 0.0146 - acc: 0.9950 - val_loss: 0.0691 - val_acc: 0.9829\n",
      "Epoch 39/40\n",
      "60000/60000 [==============================] - 9s 155us/step - loss: 0.0157 - acc: 0.9950 - val_loss: 0.0692 - val_acc: 0.9832\n",
      "Epoch 40/40\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 0.0151 - acc: 0.9952 - val_loss: 0.0693 - val_acc: 0.9831\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size = batch_size, nb_epoch = nr_iterations,\n",
    "                    verbose = 1, validation_data = (X_test, Y_test))\n",
    "score = model.evaluate(X_test, Y_test, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.Adagrad(lr=0.01, epsilon=None, decay=0.0),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'TensorVariable' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-ae41e0d14a0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m history = model.fit(X_train, Y_train,\n\u001b[1;32m      2\u001b[0m                     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnr_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m                     validation_data = (X_test, Y_test))\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1625\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1626\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1627\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1628\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_make_train_function\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    988\u001b[0m                     training_updates = self.optimizer.get_updates(\n\u001b[1;32m    989\u001b[0m                         \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_collected_trainable_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m                         loss=self.total_loss)\n\u001b[0m\u001b[1;32m    991\u001b[0m                 \u001b[0mupdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtraining_updates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m                 \u001b[0;31m# Gets loss and metrics. Updates weights at each call.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/optimizers.pyc\u001b[0m in \u001b[0;36mget_updates\u001b[0;34m(self, loss, params)\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0mnew_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# update accumulator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             \u001b[0mnew_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_a\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0;31m# Apply constraints.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'TensorVariable' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size = batch_size, nb_epoch = nr_iterations,\n",
    "                    validation_data = (X_test, Y_test))\n",
    "score = model.evaluate(X_test, Y_test, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
