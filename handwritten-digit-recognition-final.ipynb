{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras import optimizers\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.callbacks import ReduceLROnPlateau,CSVLogger, EarlyStopping, ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from numpy.random import seed\n",
    "seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"train_mean = np.mean(X_train)\n",
    "train_std = np.std(X_train)\n",
    "X_train = (X_train-train_mean)/(train_std+1e-7)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"test_mean = np.mean(X_test)\n",
    "test_std = np.std(X_test)\n",
    "X_test = (X_test-test_mean)/(test_std+1e-7)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Dense(196, input_shape=(784,)))\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Dense(10))\n",
    "model1.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 196)               153860    \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 196)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 196)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                1970      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 155,830\n",
      "Trainable params: 155,830\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_and_fit_model_Adam(model,lr,num_epochs,num):\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=lr),\n",
    "              metrics=['accuracy'])\n",
    "    csv_logger = CSVLogger('outputs/CSV_logger_'+str(num)+'_'+str(lr)+'_'+str(num_epochs)+'.csv')\n",
    "    model_checkpoint = ModelCheckpoint('outputs/Model_checkpoint_'+str(num)+'_'+str(lr)+'_'+str(num_epochs)+'.hdf5',monitor = 'val_loss',\n",
    "                                    verbose = 1, save_best_only = True)\n",
    "    history = model.fit(X_train, Y_train,\n",
    "                    batch_size = batch_size, nb_epoch = num_epochs,\n",
    "                    verbose = 1, validation_data = (X_test, Y_test),callbacks=[csv_logger,model_checkpoint])\n",
    "    score = model.evaluate(X_test, Y_test, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.3632 - acc: 0.8895Epoch 00001: val_loss improved from inf to 0.15056, saving model to Model_checkpoint_1_0.01_20.hdf5\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 0.3628 - acc: 0.8896 - val_loss: 0.1506 - val_acc: 0.9528\n",
      "Epoch 2/20\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.2689 - acc: 0.9207Epoch 00002: val_loss improved from 0.15056 to 0.13720, saving model to Model_checkpoint_1_0.01_20.hdf5\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 0.2688 - acc: 0.9208 - val_loss: 0.1372 - val_acc: 0.9584\n",
      "Epoch 3/20\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.2509 - acc: 0.9262Epoch 00003: val_loss improved from 0.13720 to 0.12113, saving model to Model_checkpoint_1_0.01_20.hdf5\n",
      "60000/60000 [==============================] - 13s 214us/step - loss: 0.2508 - acc: 0.9262 - val_loss: 0.1211 - val_acc: 0.9657\n",
      "Epoch 4/20\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.2360 - acc: 0.9317Epoch 00004: val_loss did not improve\n",
      "60000/60000 [==============================] - 13s 221us/step - loss: 0.2360 - acc: 0.9317 - val_loss: 0.1301 - val_acc: 0.9650\n",
      "Epoch 5/20\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.2276 - acc: 0.9350Epoch 00005: val_loss did not improve\n",
      "60000/60000 [==============================] - 13s 213us/step - loss: 0.2274 - acc: 0.9350 - val_loss: 0.1304 - val_acc: 0.9646\n",
      "Epoch 6/20\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.2138 - acc: 0.9390Epoch 00006: val_loss did not improve\n",
      "60000/60000 [==============================] - 13s 210us/step - loss: 0.2138 - acc: 0.9389 - val_loss: 0.1295 - val_acc: 0.9661\n",
      "Epoch 7/20\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.2078 - acc: 0.9420Epoch 00007: val_loss did not improve\n",
      "60000/60000 [==============================] - 12s 207us/step - loss: 0.2080 - acc: 0.9420 - val_loss: 0.1316 - val_acc: 0.9667\n",
      "Epoch 8/20\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.2095 - acc: 0.9416Epoch 00008: val_loss did not improve\n",
      "60000/60000 [==============================] - 13s 216us/step - loss: 0.2094 - acc: 0.9416 - val_loss: 0.1286 - val_acc: 0.9686\n",
      "Epoch 9/20\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.2052 - acc: 0.9438Epoch 00009: val_loss did not improve\n",
      "60000/60000 [==============================] - 13s 223us/step - loss: 0.2048 - acc: 0.9439 - val_loss: 0.1344 - val_acc: 0.9688\n",
      "Epoch 10/20\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.2042 - acc: 0.9450Epoch 00010: val_loss did not improve\n",
      "60000/60000 [==============================] - 13s 220us/step - loss: 0.2043 - acc: 0.9451 - val_loss: 0.1319 - val_acc: 0.9691\n",
      "Epoch 11/20\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.1984 - acc: 0.9463Epoch 00011: val_loss did not improve\n",
      "60000/60000 [==============================] - 13s 220us/step - loss: 0.1983 - acc: 0.9463 - val_loss: 0.1292 - val_acc: 0.9685\n",
      "Epoch 12/20\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.1976 - acc: 0.9465Epoch 00012: val_loss did not improve\n",
      "60000/60000 [==============================] - 13s 217us/step - loss: 0.1978 - acc: 0.9464 - val_loss: 0.1361 - val_acc: 0.9718\n",
      "Epoch 13/20\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.1992 - acc: 0.9459Epoch 00013: val_loss did not improve\n",
      "60000/60000 [==============================] - 13s 216us/step - loss: 0.1994 - acc: 0.9458 - val_loss: 0.1382 - val_acc: 0.9703\n",
      "Epoch 14/20\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.2015 - acc: 0.9467Epoch 00014: val_loss did not improve\n",
      "60000/60000 [==============================] - 13s 210us/step - loss: 0.2018 - acc: 0.9467 - val_loss: 0.1343 - val_acc: 0.9726\n",
      "Epoch 15/20\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.1862 - acc: 0.9500Epoch 00015: val_loss did not improve\n",
      "60000/60000 [==============================] - 13s 210us/step - loss: 0.1867 - acc: 0.9499 - val_loss: 0.1412 - val_acc: 0.9709\n",
      "Epoch 16/20\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.1959 - acc: 0.9478Epoch 00016: val_loss did not improve\n",
      "60000/60000 [==============================] - 13s 215us/step - loss: 0.1959 - acc: 0.9477 - val_loss: 0.1543 - val_acc: 0.9673\n",
      "Epoch 17/20\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.1936 - acc: 0.9491Epoch 00017: val_loss did not improve\n",
      "60000/60000 [==============================] - 13s 214us/step - loss: 0.1937 - acc: 0.9491 - val_loss: 0.1512 - val_acc: 0.9686\n",
      "Epoch 18/20\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.1850 - acc: 0.9516Epoch 00018: val_loss did not improve\n",
      "60000/60000 [==============================] - 13s 219us/step - loss: 0.1851 - acc: 0.9515 - val_loss: 0.1564 - val_acc: 0.9693\n",
      "Epoch 19/20\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.1895 - acc: 0.9505Epoch 00019: val_loss did not improve\n",
      "60000/60000 [==============================] - 14s 226us/step - loss: 0.1896 - acc: 0.9505 - val_loss: 0.1445 - val_acc: 0.9696\n",
      "Epoch 20/20\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.1857 - acc: 0.9512Epoch 00020: val_loss did not improve\n",
      "60000/60000 [==============================] - 13s 225us/step - loss: 0.1860 - acc: 0.9511 - val_loss: 0.1549 - val_acc: 0.9701\n"
     ]
    }
   ],
   "source": [
    "compile_and_fit_model_Adam(model1,0.01,20,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(128, input_shape=(784,)))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(10))\n",
    "model2.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.3899 - acc: 0.8803Epoch 00001: val_loss improved from inf to 0.17009, saving model to Model_checkpoint_2_0.01_20.hdf5\n",
      "60000/60000 [==============================] - 7s 124us/step - loss: 0.3897 - acc: 0.8804 - val_loss: 0.1701 - val_acc: 0.9489\n",
      "Epoch 2/20\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.2898 - acc: 0.9112Epoch 00002: val_loss improved from 0.17009 to 0.14988, saving model to Model_checkpoint_2_0.01_20.hdf5\n",
      "60000/60000 [==============================] - 8s 134us/step - loss: 0.2894 - acc: 0.9112 - val_loss: 0.1499 - val_acc: 0.9579\n",
      "Epoch 3/20\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.2597 - acc: 0.9218Epoch 00003: val_loss improved from 0.14988 to 0.14770, saving model to Model_checkpoint_2_0.01_20.hdf5\n",
      "60000/60000 [==============================] - 9s 144us/step - loss: 0.2591 - acc: 0.9220 - val_loss: 0.1477 - val_acc: 0.9589\n",
      "Epoch 4/20\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.2438 - acc: 0.9276Epoch 00004: val_loss improved from 0.14770 to 0.12821, saving model to Model_checkpoint_2_0.01_20.hdf5\n",
      "60000/60000 [==============================] - 8s 140us/step - loss: 0.2438 - acc: 0.9276 - val_loss: 0.1282 - val_acc: 0.9643\n",
      "Epoch 5/20\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.2354 - acc: 0.9315Epoch 00005: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 138us/step - loss: 0.2353 - acc: 0.9315 - val_loss: 0.1357 - val_acc: 0.9647\n",
      "Epoch 6/20\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.2332 - acc: 0.9308Epoch 00006: val_loss did not improve\n",
      "60000/60000 [==============================] - 9s 142us/step - loss: 0.2335 - acc: 0.9306 - val_loss: 0.1382 - val_acc: 0.9653\n",
      "Epoch 7/20\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.2316 - acc: 0.9326Epoch 00007: val_loss improved from 0.12821 to 0.12220, saving model to Model_checkpoint_2_0.01_20.hdf5\n",
      "60000/60000 [==============================] - 9s 145us/step - loss: 0.2317 - acc: 0.9327 - val_loss: 0.1222 - val_acc: 0.9677\n",
      "Epoch 8/20\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.2214 - acc: 0.9359Epoch 00008: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 141us/step - loss: 0.2212 - acc: 0.9360 - val_loss: 0.1337 - val_acc: 0.9681\n",
      "Epoch 9/20\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.2174 - acc: 0.9376Epoch 00009: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 139us/step - loss: 0.2177 - acc: 0.9375 - val_loss: 0.1343 - val_acc: 0.9646\n",
      "Epoch 10/20\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.2184 - acc: 0.9375Epoch 00010: val_loss did not improve\n",
      "60000/60000 [==============================] - 9s 145us/step - loss: 0.2184 - acc: 0.9376 - val_loss: 0.1388 - val_acc: 0.9657\n",
      "Epoch 11/20\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.2190 - acc: 0.9383Epoch 00011: val_loss did not improve\n",
      "60000/60000 [==============================] - 9s 145us/step - loss: 0.2192 - acc: 0.9383 - val_loss: 0.1322 - val_acc: 0.9680\n",
      "Epoch 12/20\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.2090 - acc: 0.9406Epoch 00012: val_loss did not improve\n",
      "60000/60000 [==============================] - 9s 147us/step - loss: 0.2086 - acc: 0.9407 - val_loss: 0.1399 - val_acc: 0.9689\n",
      "Epoch 13/20\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.2078 - acc: 0.9411Epoch 00013: val_loss did not improve\n",
      "60000/60000 [==============================] - 9s 147us/step - loss: 0.2077 - acc: 0.9411 - val_loss: 0.1457 - val_acc: 0.9659\n",
      "Epoch 14/20\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.2028 - acc: 0.9434Epoch 00014: val_loss did not improve\n",
      "60000/60000 [==============================] - 9s 142us/step - loss: 0.2028 - acc: 0.9434 - val_loss: 0.1497 - val_acc: 0.9679\n",
      "Epoch 15/20\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.2084 - acc: 0.9429Epoch 00015: val_loss did not improve\n",
      "60000/60000 [==============================] - 9s 143us/step - loss: 0.2084 - acc: 0.9429 - val_loss: 0.1306 - val_acc: 0.9685\n",
      "Epoch 16/20\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.1991 - acc: 0.9452Epoch 00016: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 141us/step - loss: 0.1998 - acc: 0.9451 - val_loss: 0.1378 - val_acc: 0.9703\n",
      "Epoch 17/20\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.1994 - acc: 0.9454Epoch 00017: val_loss did not improve\n",
      "60000/60000 [==============================] - 9s 146us/step - loss: 0.1998 - acc: 0.9453 - val_loss: 0.1405 - val_acc: 0.9707\n",
      "Epoch 18/20\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.2036 - acc: 0.9440Epoch 00018: val_loss did not improve\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.2033 - acc: 0.9441 - val_loss: 0.1420 - val_acc: 0.9698\n",
      "Epoch 19/20\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.1945 - acc: 0.9465Epoch 00019: val_loss did not improve\n",
      "60000/60000 [==============================] - 9s 148us/step - loss: 0.1949 - acc: 0.9464 - val_loss: 0.1438 - val_acc: 0.9695\n",
      "Epoch 20/20\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.1947 - acc: 0.9453Epoch 00020: val_loss did not improve\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.1947 - acc: 0.9453 - val_loss: 0.1438 - val_acc: 0.9704\n"
     ]
    }
   ],
   "source": [
    "compile_and_fit_model_Adam(model2,0.01,20,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.1575 - acc: 0.9600Epoch 00001: val_loss improved from inf to 0.17888, saving model to Model_checkpoint_2_0.01_30.hdf5\n",
      "60000/60000 [==============================] - 7s 125us/step - loss: 0.1574 - acc: 0.9600 - val_loss: 0.1789 - val_acc: 0.9709\n",
      "Epoch 2/30\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.1751 - acc: 0.9554Epoch 00002: val_loss improved from 0.17888 to 0.17826, saving model to Model_checkpoint_2_0.01_30.hdf5\n",
      "60000/60000 [==============================] - 8s 129us/step - loss: 0.1747 - acc: 0.9555 - val_loss: 0.1783 - val_acc: 0.9703\n",
      "Epoch 3/30\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.1841 - acc: 0.9543Epoch 00003: val_loss improved from 0.17826 to 0.15734, saving model to Model_checkpoint_2_0.01_30.hdf5\n",
      "60000/60000 [==============================] - 8s 132us/step - loss: 0.1840 - acc: 0.9544 - val_loss: 0.1573 - val_acc: 0.9695\n",
      "Epoch 4/30\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.1831 - acc: 0.9534Epoch 00004: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 129us/step - loss: 0.1832 - acc: 0.9533 - val_loss: 0.1773 - val_acc: 0.9717\n",
      "Epoch 5/30\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.1846 - acc: 0.9540Epoch 00005: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 132us/step - loss: 0.1844 - acc: 0.9540 - val_loss: 0.1655 - val_acc: 0.9699\n",
      "Epoch 6/30\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.1800 - acc: 0.9540Epoch 00006: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 0.1801 - acc: 0.9540 - val_loss: 0.1755 - val_acc: 0.9692\n",
      "Epoch 7/30\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.1790 - acc: 0.9547Epoch 00007: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 134us/step - loss: 0.1790 - acc: 0.9546 - val_loss: 0.1824 - val_acc: 0.9700\n",
      "Epoch 8/30\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.1704 - acc: 0.9568Epoch 00008: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 135us/step - loss: 0.1705 - acc: 0.9568 - val_loss: 0.1808 - val_acc: 0.9675\n",
      "Epoch 9/30\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.1783 - acc: 0.9553Epoch 00009: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 131us/step - loss: 0.1782 - acc: 0.9553 - val_loss: 0.1782 - val_acc: 0.9706\n",
      "Epoch 10/30\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.1739 - acc: 0.9557Epoch 00010: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 134us/step - loss: 0.1737 - acc: 0.9558 - val_loss: 0.1715 - val_acc: 0.9718\n",
      "Epoch 11/30\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.1778 - acc: 0.9549Epoch 00011: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 133us/step - loss: 0.1778 - acc: 0.9549 - val_loss: 0.1649 - val_acc: 0.9696\n",
      "Epoch 12/30\n",
      "59520/60000 [============================>.] - ETA: 0s - loss: 0.1752 - acc: 0.9561Epoch 00012: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 132us/step - loss: 0.1753 - acc: 0.9561 - val_loss: 0.1676 - val_acc: 0.9706\n",
      "Epoch 13/30\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.1776 - acc: 0.9549Epoch 00013: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 137us/step - loss: 0.1775 - acc: 0.9550 - val_loss: 0.1912 - val_acc: 0.9701\n",
      "Epoch 14/30\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.1825 - acc: 0.9551Epoch 00014: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 140us/step - loss: 0.1824 - acc: 0.9551 - val_loss: 0.1764 - val_acc: 0.9698\n",
      "Epoch 15/30\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.1805 - acc: 0.9551Epoch 00015: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 136us/step - loss: 0.1810 - acc: 0.9551 - val_loss: 0.1970 - val_acc: 0.9702\n",
      "Epoch 16/30\n",
      "59520/60000 [============================>.] - ETA: 0s - loss: 0.1792 - acc: 0.9560Epoch 00016: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 138us/step - loss: 0.1793 - acc: 0.9560 - val_loss: 0.1736 - val_acc: 0.9713\n",
      "Epoch 17/30\n",
      "59520/60000 [============================>.] - ETA: 0s - loss: 0.1805 - acc: 0.9568Epoch 00017: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 137us/step - loss: 0.1808 - acc: 0.9568 - val_loss: 0.1691 - val_acc: 0.9728\n",
      "Epoch 18/30\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.1613 - acc: 0.9588Epoch 00018: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 136us/step - loss: 0.1615 - acc: 0.9587 - val_loss: 0.1836 - val_acc: 0.9695\n",
      "Epoch 19/30\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.1764 - acc: 0.9579Epoch 00019: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 141us/step - loss: 0.1762 - acc: 0.9579 - val_loss: 0.1847 - val_acc: 0.9696\n",
      "Epoch 20/30\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.1786 - acc: 0.9552Epoch 00020: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 135us/step - loss: 0.1785 - acc: 0.9553 - val_loss: 0.1733 - val_acc: 0.9707\n",
      "Epoch 21/30\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.1702 - acc: 0.9568Epoch 00021: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 134us/step - loss: 0.1699 - acc: 0.9569 - val_loss: 0.1880 - val_acc: 0.9696\n",
      "Epoch 22/30\n",
      "59520/60000 [============================>.] - ETA: 0s - loss: 0.1724 - acc: 0.9565Epoch 00022: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 135us/step - loss: 0.1719 - acc: 0.9566 - val_loss: 0.1994 - val_acc: 0.9684\n",
      "Epoch 23/30\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.1789 - acc: 0.9562Epoch 00023: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 137us/step - loss: 0.1787 - acc: 0.9563 - val_loss: 0.1953 - val_acc: 0.9694\n",
      "Epoch 24/30\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.1785 - acc: 0.9558Epoch 00024: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 140us/step - loss: 0.1785 - acc: 0.9558 - val_loss: 0.2104 - val_acc: 0.9685\n",
      "Epoch 25/30\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.1770 - acc: 0.9569Epoch 00025: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 140us/step - loss: 0.1766 - acc: 0.9569 - val_loss: 0.1911 - val_acc: 0.9685\n",
      "Epoch 26/30\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.1789 - acc: 0.9555Epoch 00026: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 141us/step - loss: 0.1791 - acc: 0.9555 - val_loss: 0.1908 - val_acc: 0.9711\n",
      "Epoch 27/30\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.1680 - acc: 0.9584Epoch 00027: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 137us/step - loss: 0.1680 - acc: 0.9585 - val_loss: 0.1970 - val_acc: 0.9690\n",
      "Epoch 28/30\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.1680 - acc: 0.9592Epoch 00028: val_loss did not improve\n",
      "60000/60000 [==============================] - 9s 142us/step - loss: 0.1691 - acc: 0.9591 - val_loss: 0.1875 - val_acc: 0.9698\n",
      "Epoch 29/30\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.1699 - acc: 0.9580Epoch 00029: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 139us/step - loss: 0.1697 - acc: 0.9580 - val_loss: 0.1759 - val_acc: 0.9719\n",
      "Epoch 30/30\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.1699 - acc: 0.9581Epoch 00030: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 136us/step - loss: 0.1696 - acc: 0.9582 - val_loss: 0.1956 - val_acc: 0.9687\n"
     ]
    }
   ],
   "source": [
    "compile_and_fit_model_Adam(model2,0.01,30,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.1454 - acc: 0.9605Epoch 00001: val_loss improved from inf to 0.13111, saving model to Model_checkpoint_2_0.001_30.hdf5\n",
      "60000/60000 [==============================] - 7s 124us/step - loss: 0.1459 - acc: 0.9604 - val_loss: 0.1311 - val_acc: 0.9748\n",
      "Epoch 2/30\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.1245 - acc: 0.9636Epoch 00002: val_loss improved from 0.13111 to 0.12924, saving model to Model_checkpoint_2_0.001_30.hdf5\n",
      "60000/60000 [==============================] - 8s 129us/step - loss: 0.1243 - acc: 0.9637 - val_loss: 0.1292 - val_acc: 0.9739\n",
      "Epoch 3/30\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.1167 - acc: 0.9668Epoch 00003: val_loss improved from 0.12924 to 0.12904, saving model to Model_checkpoint_2_0.001_30.hdf5\n",
      "60000/60000 [==============================] - 8s 139us/step - loss: 0.1166 - acc: 0.9668 - val_loss: 0.1290 - val_acc: 0.9744\n",
      "Epoch 4/30\n",
      "59520/60000 [============================>.] - ETA: 0s - loss: 0.1099 - acc: 0.9684Epoch 00004: val_loss improved from 0.12904 to 0.12868, saving model to Model_checkpoint_2_0.001_30.hdf5\n",
      "60000/60000 [==============================] - 8s 129us/step - loss: 0.1096 - acc: 0.9685 - val_loss: 0.1287 - val_acc: 0.9744\n",
      "Epoch 5/30\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.1082 - acc: 0.9676Epoch 00005: val_loss improved from 0.12868 to 0.12744, saving model to Model_checkpoint_2_0.001_30.hdf5\n",
      "60000/60000 [==============================] - 8s 133us/step - loss: 0.1082 - acc: 0.9676 - val_loss: 0.1274 - val_acc: 0.9752\n",
      "Epoch 6/30\n",
      "59520/60000 [============================>.] - ETA: 0s - loss: 0.1035 - acc: 0.9694Epoch 00006: val_loss improved from 0.12744 to 0.12439, saving model to Model_checkpoint_2_0.001_30.hdf5\n",
      "60000/60000 [==============================] - 8s 136us/step - loss: 0.1042 - acc: 0.9693 - val_loss: 0.1244 - val_acc: 0.9756\n",
      "Epoch 7/30\n",
      "59520/60000 [============================>.] - ETA: 0s - loss: 0.1004 - acc: 0.9699Epoch 00007: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 135us/step - loss: 0.1004 - acc: 0.9699 - val_loss: 0.1257 - val_acc: 0.9767\n",
      "Epoch 8/30\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.0986 - acc: 0.9707Epoch 00008: val_loss improved from 0.12439 to 0.12323, saving model to Model_checkpoint_2_0.001_30.hdf5\n",
      "60000/60000 [==============================] - 8s 133us/step - loss: 0.0985 - acc: 0.9707 - val_loss: 0.1232 - val_acc: 0.9759\n",
      "Epoch 9/30\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.0971 - acc: 0.9704Epoch 00009: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 128us/step - loss: 0.0970 - acc: 0.9704 - val_loss: 0.1242 - val_acc: 0.9755\n",
      "Epoch 10/30\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.0949 - acc: 0.9704Epoch 00010: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 128us/step - loss: 0.0948 - acc: 0.9704 - val_loss: 0.1243 - val_acc: 0.9770\n",
      "Epoch 11/30\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.0947 - acc: 0.9718Epoch 00011: val_loss improved from 0.12323 to 0.12159, saving model to Model_checkpoint_2_0.001_30.hdf5\n",
      "60000/60000 [==============================] - 8s 134us/step - loss: 0.0946 - acc: 0.9718 - val_loss: 0.1216 - val_acc: 0.9765\n",
      "Epoch 12/30\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.0941 - acc: 0.9718Epoch 00012: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 136us/step - loss: 0.0940 - acc: 0.9718 - val_loss: 0.1228 - val_acc: 0.9758\n",
      "Epoch 13/30\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.0916 - acc: 0.9723Epoch 00013: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 132us/step - loss: 0.0918 - acc: 0.9722 - val_loss: 0.1228 - val_acc: 0.9751\n",
      "Epoch 14/30\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.0898 - acc: 0.9731Epoch 00014: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 134us/step - loss: 0.0897 - acc: 0.9731 - val_loss: 0.1216 - val_acc: 0.9767\n",
      "Epoch 15/30\n",
      "59520/60000 [============================>.] - ETA: 0s - loss: 0.0883 - acc: 0.9728Epoch 00015: val_loss improved from 0.12159 to 0.12057, saving model to Model_checkpoint_2_0.001_30.hdf5\n",
      "60000/60000 [==============================] - 8s 137us/step - loss: 0.0880 - acc: 0.9729 - val_loss: 0.1206 - val_acc: 0.9757\n",
      "Epoch 16/30\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.0896 - acc: 0.9729Epoch 00016: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 137us/step - loss: 0.0896 - acc: 0.9729 - val_loss: 0.1260 - val_acc: 0.9752\n",
      "Epoch 17/30\n",
      "59520/60000 [============================>.] - ETA: 0s - loss: 0.0890 - acc: 0.9730Epoch 00017: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 133us/step - loss: 0.0893 - acc: 0.9729 - val_loss: 0.1218 - val_acc: 0.9756\n",
      "Epoch 18/30\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.0835 - acc: 0.9736Epoch 00018: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 131us/step - loss: 0.0834 - acc: 0.9736 - val_loss: 0.1240 - val_acc: 0.9757\n",
      "Epoch 19/30\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.0828 - acc: 0.9741Epoch 00019: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 138us/step - loss: 0.0829 - acc: 0.9740 - val_loss: 0.1224 - val_acc: 0.9771\n",
      "Epoch 20/30\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.0847 - acc: 0.9737Epoch 00020: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 132us/step - loss: 0.0847 - acc: 0.9738 - val_loss: 0.1231 - val_acc: 0.9762\n",
      "Epoch 21/30\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.0857 - acc: 0.9741Epoch 00021: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 137us/step - loss: 0.0855 - acc: 0.9742 - val_loss: 0.1217 - val_acc: 0.9762\n",
      "Epoch 22/30\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.0810 - acc: 0.9753Epoch 00022: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 134us/step - loss: 0.0809 - acc: 0.9753 - val_loss: 0.1226 - val_acc: 0.9769\n",
      "Epoch 23/30\n",
      "59520/60000 [============================>.] - ETA: 0s - loss: 0.0835 - acc: 0.9742Epoch 00023: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 135us/step - loss: 0.0837 - acc: 0.9742 - val_loss: 0.1232 - val_acc: 0.9760\n",
      "Epoch 24/30\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.0784 - acc: 0.9757Epoch 00024: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 133us/step - loss: 0.0785 - acc: 0.9756 - val_loss: 0.1239 - val_acc: 0.9756\n",
      "Epoch 25/30\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.0813 - acc: 0.9748Epoch 00025: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 137us/step - loss: 0.0813 - acc: 0.9747 - val_loss: 0.1241 - val_acc: 0.9758\n",
      "Epoch 26/30\n",
      "59520/60000 [============================>.] - ETA: 0s - loss: 0.0820 - acc: 0.9742Epoch 00026: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 141us/step - loss: 0.0818 - acc: 0.9743 - val_loss: 0.1250 - val_acc: 0.9763\n",
      "Epoch 27/30\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.0780 - acc: 0.9760Epoch 00027: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 138us/step - loss: 0.0783 - acc: 0.9759 - val_loss: 0.1252 - val_acc: 0.9760\n",
      "Epoch 28/30\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.0808 - acc: 0.9756Epoch 00028: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 136us/step - loss: 0.0807 - acc: 0.9756 - val_loss: 0.1234 - val_acc: 0.9755\n",
      "Epoch 29/30\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.0781 - acc: 0.9753Epoch 00029: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 136us/step - loss: 0.0781 - acc: 0.9753 - val_loss: 0.1289 - val_acc: 0.9752\n",
      "Epoch 30/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.0772 - acc: 0.9764Epoch 00030: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 135us/step - loss: 0.0772 - acc: 0.9764 - val_loss: 0.1281 - val_acc: 0.9758\n"
     ]
    }
   ],
   "source": [
    "compile_and_fit_model_Adam(model2,0.001,30,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.0765 - acc: 0.9767Epoch 00001: val_loss improved from inf to 0.12836, saving model to Model_checkpoint_2_0.0001_30.hdf5\n",
      "60000/60000 [==============================] - 8s 129us/step - loss: 0.0765 - acc: 0.9767 - val_loss: 0.1284 - val_acc: 0.9761\n",
      "Epoch 2/30\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.0747 - acc: 0.9771Epoch 00002: val_loss improved from 0.12836 to 0.12809, saving model to Model_checkpoint_2_0.0001_30.hdf5\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.0748 - acc: 0.9771 - val_loss: 0.1281 - val_acc: 0.9760\n",
      "Epoch 3/30\n",
      "59520/60000 [============================>.] - ETA: 0s - loss: 0.0737 - acc: 0.9775Epoch 00003: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 135us/step - loss: 0.0735 - acc: 0.9775 - val_loss: 0.1284 - val_acc: 0.9760\n",
      "Epoch 4/30\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.0705 - acc: 0.9786Epoch 00004: val_loss improved from 0.12809 to 0.12801, saving model to Model_checkpoint_2_0.0001_30.hdf5\n",
      "60000/60000 [==============================] - 8s 137us/step - loss: 0.0707 - acc: 0.9785 - val_loss: 0.1280 - val_acc: 0.9758\n",
      "Epoch 5/30\n",
      "59520/60000 [============================>.] - ETA: 0s - loss: 0.0730 - acc: 0.9772Epoch 00005: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 0.0733 - acc: 0.9771 - val_loss: 0.1284 - val_acc: 0.9756\n",
      "Epoch 6/30\n",
      "59520/60000 [============================>.] - ETA: 0s - loss: 0.0713 - acc: 0.9782Epoch 00006: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 132us/step - loss: 0.0715 - acc: 0.9781 - val_loss: 0.1283 - val_acc: 0.9756\n",
      "Epoch 7/30\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.0703 - acc: 0.9784Epoch 00007: val_loss improved from 0.12801 to 0.12773, saving model to Model_checkpoint_2_0.0001_30.hdf5\n",
      "60000/60000 [==============================] - 8s 134us/step - loss: 0.0702 - acc: 0.9784 - val_loss: 0.1277 - val_acc: 0.9757\n",
      "Epoch 8/30\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.0704 - acc: 0.9786Epoch 00008: val_loss improved from 0.12773 to 0.12769, saving model to Model_checkpoint_2_0.0001_30.hdf5\n",
      "60000/60000 [==============================] - 8s 141us/step - loss: 0.0703 - acc: 0.9787 - val_loss: 0.1277 - val_acc: 0.9756\n",
      "Epoch 9/30\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.0708 - acc: 0.9776Epoch 00009: val_loss improved from 0.12769 to 0.12751, saving model to Model_checkpoint_2_0.0001_30.hdf5\n",
      "60000/60000 [==============================] - 8s 137us/step - loss: 0.0708 - acc: 0.9776 - val_loss: 0.1275 - val_acc: 0.9757\n",
      "Epoch 10/30\n",
      "59520/60000 [============================>.] - ETA: 0s - loss: 0.0711 - acc: 0.9777Epoch 00010: val_loss improved from 0.12751 to 0.12736, saving model to Model_checkpoint_2_0.0001_30.hdf5\n",
      "60000/60000 [==============================] - 8s 132us/step - loss: 0.0711 - acc: 0.9777 - val_loss: 0.1274 - val_acc: 0.9758\n",
      "Epoch 11/30\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.0706 - acc: 0.9776Epoch 00011: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 131us/step - loss: 0.0706 - acc: 0.9776 - val_loss: 0.1278 - val_acc: 0.9758\n",
      "Epoch 12/30\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.0704 - acc: 0.9783Epoch 00012: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 0.0703 - acc: 0.9783 - val_loss: 0.1275 - val_acc: 0.9758\n",
      "Epoch 13/30\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.0715 - acc: 0.9781Epoch 00013: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 132us/step - loss: 0.0715 - acc: 0.9781 - val_loss: 0.1277 - val_acc: 0.9758\n",
      "Epoch 14/30\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.0687 - acc: 0.9784Epoch 00014: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 129us/step - loss: 0.0688 - acc: 0.9784 - val_loss: 0.1278 - val_acc: 0.9758\n",
      "Epoch 15/30\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.0724 - acc: 0.9772Epoch 00015: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 134us/step - loss: 0.0724 - acc: 0.9773 - val_loss: 0.1283 - val_acc: 0.9755\n",
      "Epoch 16/30\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.0711 - acc: 0.9784Epoch 00016: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 133us/step - loss: 0.0712 - acc: 0.9784 - val_loss: 0.1281 - val_acc: 0.9756\n",
      "Epoch 17/30\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.0678 - acc: 0.9793Epoch 00017: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 136us/step - loss: 0.0677 - acc: 0.9793 - val_loss: 0.1279 - val_acc: 0.9757\n",
      "Epoch 18/30\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.0699 - acc: 0.9783Epoch 00018: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 0.0698 - acc: 0.9783 - val_loss: 0.1286 - val_acc: 0.9756\n",
      "Epoch 19/30\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.0682 - acc: 0.9782Epoch 00019: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 133us/step - loss: 0.0684 - acc: 0.9782 - val_loss: 0.1292 - val_acc: 0.9758\n",
      "Epoch 20/30\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.0690 - acc: 0.9787Epoch 00020: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 140us/step - loss: 0.0689 - acc: 0.9788 - val_loss: 0.1291 - val_acc: 0.9755\n",
      "Epoch 21/30\n",
      "59520/60000 [============================>.] - ETA: 0s - loss: 0.0689 - acc: 0.9787Epoch 00021: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 0.0688 - acc: 0.9787 - val_loss: 0.1296 - val_acc: 0.9757\n",
      "Epoch 22/30\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.0692 - acc: 0.9777Epoch 00022: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 131us/step - loss: 0.0693 - acc: 0.9777 - val_loss: 0.1296 - val_acc: 0.9754\n",
      "Epoch 23/30\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.0656 - acc: 0.9793Epoch 00023: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 128us/step - loss: 0.0655 - acc: 0.9793 - val_loss: 0.1292 - val_acc: 0.9757\n",
      "Epoch 24/30\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.0688 - acc: 0.9786Epoch 00024: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 0.0689 - acc: 0.9786 - val_loss: 0.1301 - val_acc: 0.9755\n",
      "Epoch 25/30\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.0701 - acc: 0.9783Epoch 00025: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 134us/step - loss: 0.0700 - acc: 0.9783 - val_loss: 0.1288 - val_acc: 0.9753\n",
      "Epoch 26/30\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.0678 - acc: 0.9786Epoch 00026: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 0.0678 - acc: 0.9786 - val_loss: 0.1286 - val_acc: 0.9757\n",
      "Epoch 27/30\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.0703 - acc: 0.9784Epoch 00027: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 133us/step - loss: 0.0702 - acc: 0.9785 - val_loss: 0.1284 - val_acc: 0.9758\n",
      "Epoch 28/30\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.0706 - acc: 0.9782Epoch 00028: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 134us/step - loss: 0.0706 - acc: 0.9781 - val_loss: 0.1293 - val_acc: 0.9759\n",
      "Epoch 29/30\n",
      "59520/60000 [============================>.] - ETA: 0s - loss: 0.0668 - acc: 0.9786Epoch 00029: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 132us/step - loss: 0.0667 - acc: 0.9786 - val_loss: 0.1302 - val_acc: 0.9754\n",
      "Epoch 30/30\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.0718 - acc: 0.9778Epoch 00030: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 132us/step - loss: 0.0717 - acc: 0.9778 - val_loss: 0.1299 - val_acc: 0.9757\n"
     ]
    }
   ],
   "source": [
    "compile_and_fit_model_Adam(model2,0.0001,30,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_and_fit_model_SGD(model,lr,num_epochs,num):\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=lr),\n",
    "              metrics=['accuracy'])\n",
    "    csv_logger = CSVLogger('outputs/CSV_logger_SGD_'+str(num)+'_'+str(lr)+'_'+str(num_epochs)+'.csv')\n",
    "    model_checkpoint = ModelCheckpoint('outputs/Model_checkpoint_SGD_'+str(num)+'_'+str(lr)+'_'+str(num_epochs)+'.hdf5',monitor = 'val_loss',\n",
    "                                    verbose = 1, save_best_only = True)\n",
    "    history = model.fit(X_train, Y_train,\n",
    "                    batch_size = batch_size, nb_epoch = num_epochs,\n",
    "                    verbose = 1, validation_data = (X_test, Y_test),callbacks=[csv_logger,model_checkpoint])\n",
    "    score = model.evaluate(X_test, Y_test, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.1686 - acc: 0.9537Epoch 00001: val_loss improved from inf to 0.14475, saving model to Model_checkpoint_SGD_2_0.01_20.hdf5\n",
      "60000/60000 [==============================] - 7s 124us/step - loss: 0.1686 - acc: 0.9537 - val_loss: 0.1447 - val_acc: 0.9712\n",
      "Epoch 2/20\n",
      "59520/60000 [============================>.] - ETA: 0s - loss: 0.1772 - acc: 0.9514Epoch 00002: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 133us/step - loss: 0.1779 - acc: 0.9513 - val_loss: 0.1737 - val_acc: 0.9681\n",
      "Epoch 3/20\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.1886 - acc: 0.9500Epoch 00003: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 135us/step - loss: 0.1888 - acc: 0.9500 - val_loss: 0.1489 - val_acc: 0.9699\n",
      "Epoch 4/20\n",
      "59520/60000 [============================>.] - ETA: 0s - loss: 0.1883 - acc: 0.9495Epoch 00004: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 135us/step - loss: 0.1886 - acc: 0.9495 - val_loss: 0.1472 - val_acc: 0.9716\n",
      "Epoch 5/20\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.1916 - acc: 0.9491Epoch 00005: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 140us/step - loss: 0.1917 - acc: 0.9490 - val_loss: 0.1555 - val_acc: 0.9689\n",
      "Epoch 6/20\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.1977 - acc: 0.9487Epoch 00006: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 138us/step - loss: 0.1976 - acc: 0.9487 - val_loss: 0.1525 - val_acc: 0.9701\n",
      "Epoch 7/20\n",
      "59520/60000 [============================>.] - ETA: 0s - loss: 0.1811 - acc: 0.9514Epoch 00007: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 0.1812 - acc: 0.9515 - val_loss: 0.1554 - val_acc: 0.9692\n",
      "Epoch 8/20\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.1893 - acc: 0.9502Epoch 00008: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 138us/step - loss: 0.1892 - acc: 0.9502 - val_loss: 0.1561 - val_acc: 0.9695\n",
      "Epoch 9/20\n",
      "59520/60000 [============================>.] - ETA: 0s - loss: 0.1810 - acc: 0.9517Epoch 00009: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 138us/step - loss: 0.1815 - acc: 0.9516 - val_loss: 0.1716 - val_acc: 0.9688\n",
      "Epoch 10/20\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.1891 - acc: 0.9509Epoch 00010: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 136us/step - loss: 0.1894 - acc: 0.9509 - val_loss: 0.1597 - val_acc: 0.9699\n",
      "Epoch 11/20\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.1812 - acc: 0.9519Epoch 00011: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 136us/step - loss: 0.1811 - acc: 0.9518 - val_loss: 0.1585 - val_acc: 0.9699\n",
      "Epoch 12/20\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.1853 - acc: 0.9510Epoch 00012: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 137us/step - loss: 0.1853 - acc: 0.9510 - val_loss: 0.1627 - val_acc: 0.9704\n",
      "Epoch 13/20\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.1836 - acc: 0.9518Epoch 00013: val_loss did not improve\n",
      "60000/60000 [==============================] - 9s 143us/step - loss: 0.1835 - acc: 0.9518 - val_loss: 0.1492 - val_acc: 0.9700\n",
      "Epoch 14/20\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.1886 - acc: 0.9499Epoch 00014: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 137us/step - loss: 0.1885 - acc: 0.9498 - val_loss: 0.1605 - val_acc: 0.9713\n",
      "Epoch 15/20\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.1787 - acc: 0.9530Epoch 00015: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 137us/step - loss: 0.1785 - acc: 0.9530 - val_loss: 0.1540 - val_acc: 0.9712\n",
      "Epoch 16/20\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.1843 - acc: 0.9524Epoch 00016: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 134us/step - loss: 0.1842 - acc: 0.9525 - val_loss: 0.1657 - val_acc: 0.9679\n",
      "Epoch 17/20\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.1829 - acc: 0.9527Epoch 00017: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 133us/step - loss: 0.1834 - acc: 0.9526 - val_loss: 0.1596 - val_acc: 0.9703\n",
      "Epoch 18/20\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.1831 - acc: 0.9530Epoch 00018: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 136us/step - loss: 0.1830 - acc: 0.9530 - val_loss: 0.1720 - val_acc: 0.9696\n",
      "Epoch 19/20\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.1769 - acc: 0.9528Epoch 00019: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 138us/step - loss: 0.1766 - acc: 0.9529 - val_loss: 0.1674 - val_acc: 0.9704\n",
      "Epoch 20/20\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.1806 - acc: 0.9531Epoch 00020: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 135us/step - loss: 0.1808 - acc: 0.9531 - val_loss: 0.1669 - val_acc: 0.9713\n"
     ]
    }
   ],
   "source": [
    "compile_and_fit_model_SGD(model2,0.01,20,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.1317 - acc: 0.9644Epoch 00001: val_loss improved from inf to 0.15206, saving model to Model_checkpoint_SGD_2_0.001_20.hdf5\n",
      "60000/60000 [==============================] - 7s 123us/step - loss: 0.1318 - acc: 0.9643 - val_loss: 0.1521 - val_acc: 0.9738\n",
      "Epoch 2/20\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.1122 - acc: 0.9693Epoch 00002: val_loss improved from 0.15206 to 0.15033, saving model to Model_checkpoint_SGD_2_0.001_20.hdf5\n",
      "60000/60000 [==============================] - 7s 124us/step - loss: 0.1120 - acc: 0.9694 - val_loss: 0.1503 - val_acc: 0.9740\n",
      "Epoch 3/20\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.0992 - acc: 0.9718Epoch 00003: val_loss did not improve\n",
      "60000/60000 [==============================] - 7s 125us/step - loss: 0.0991 - acc: 0.9718 - val_loss: 0.1556 - val_acc: 0.9742\n",
      "Epoch 4/20\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.0988 - acc: 0.9720Epoch 00004: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 125us/step - loss: 0.0988 - acc: 0.9720 - val_loss: 0.1511 - val_acc: 0.9750\n",
      "Epoch 5/20\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.0949 - acc: 0.9731Epoch 00005: val_loss improved from 0.15033 to 0.14987, saving model to Model_checkpoint_SGD_2_0.001_20.hdf5\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 0.0948 - acc: 0.9731 - val_loss: 0.1499 - val_acc: 0.9741\n",
      "Epoch 6/20\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.0906 - acc: 0.9737Epoch 00006: val_loss did not improve\n",
      "60000/60000 [==============================] - 7s 125us/step - loss: 0.0908 - acc: 0.9737 - val_loss: 0.1510 - val_acc: 0.9750\n",
      "Epoch 7/20\n",
      "59520/60000 [============================>.] - ETA: 0s - loss: 0.0874 - acc: 0.9748Epoch 00007: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 129us/step - loss: 0.0874 - acc: 0.9748 - val_loss: 0.1525 - val_acc: 0.9742\n",
      "Epoch 8/20\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.0866 - acc: 0.9747Epoch 00008: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 129us/step - loss: 0.0866 - acc: 0.9747 - val_loss: 0.1524 - val_acc: 0.9751\n",
      "Epoch 9/20\n",
      "59520/60000 [============================>.] - ETA: 0s - loss: 0.0834 - acc: 0.9753Epoch 00009: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.0836 - acc: 0.9753 - val_loss: 0.1526 - val_acc: 0.9748\n",
      "Epoch 10/20\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.0864 - acc: 0.9750Epoch 00010: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 0.0863 - acc: 0.9750 - val_loss: 0.1514 - val_acc: 0.9744\n",
      "Epoch 11/20\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.0830 - acc: 0.9749Epoch 00011: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 0.0832 - acc: 0.9748 - val_loss: 0.1541 - val_acc: 0.9746\n",
      "Epoch 12/20\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.0801 - acc: 0.9760Epoch 00012: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 129us/step - loss: 0.0802 - acc: 0.9760 - val_loss: 0.1558 - val_acc: 0.9750\n",
      "Epoch 13/20\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.0817 - acc: 0.9760Epoch 00013: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 129us/step - loss: 0.0821 - acc: 0.9759 - val_loss: 0.1566 - val_acc: 0.9752\n",
      "Epoch 14/20\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.0791 - acc: 0.9766Epoch 00014: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 128us/step - loss: 0.0790 - acc: 0.9766 - val_loss: 0.1519 - val_acc: 0.9746\n",
      "Epoch 15/20\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.0757 - acc: 0.9772Epoch 00015: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 129us/step - loss: 0.0758 - acc: 0.9772 - val_loss: 0.1541 - val_acc: 0.9749\n",
      "Epoch 16/20\n",
      "59520/60000 [============================>.] - ETA: 0s - loss: 0.0775 - acc: 0.9768Epoch 00016: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 129us/step - loss: 0.0775 - acc: 0.9768 - val_loss: 0.1537 - val_acc: 0.9749\n",
      "Epoch 17/20\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.0753 - acc: 0.9776Epoch 00017: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 0.0752 - acc: 0.9776 - val_loss: 0.1572 - val_acc: 0.9741\n",
      "Epoch 18/20\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.0769 - acc: 0.9770Epoch 00018: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 127us/step - loss: 0.0769 - acc: 0.9770 - val_loss: 0.1557 - val_acc: 0.9750\n",
      "Epoch 19/20\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.0740 - acc: 0.9777Epoch 00019: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 130us/step - loss: 0.0741 - acc: 0.9776 - val_loss: 0.1589 - val_acc: 0.9751\n",
      "Epoch 20/20\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.0761 - acc: 0.9775Epoch 00020: val_loss did not improve\n",
      "60000/60000 [==============================] - 8s 132us/step - loss: 0.0764 - acc: 0.9775 - val_loss: 0.1564 - val_acc: 0.9748\n"
     ]
    }
   ],
   "source": [
    "compile_and_fit_model_SGD(model2,0.001,20,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "model3.add(Dense(196, input_shape=(784,)))\n",
    "model3.add(Activation('tanh'))\n",
    "model3.add(Dropout(0.5))\n",
    "model3.add(Dense(10))\n",
    "model3.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.3724 - acc: 0.8868Epoch 00001: val_loss improved from inf to 0.21045, saving model to Model_checkpoint_3_0.01_30.hdf5\n",
      "60000/60000 [==============================] - 12s 205us/step - loss: 0.3722 - acc: 0.8868 - val_loss: 0.2104 - val_acc: 0.9379\n",
      "Epoch 2/30\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.2963 - acc: 0.9146Epoch 00002: val_loss improved from 0.21045 to 0.15942, saving model to Model_checkpoint_3_0.01_30.hdf5\n",
      "60000/60000 [==============================] - 14s 233us/step - loss: 0.2962 - acc: 0.9146 - val_loss: 0.1594 - val_acc: 0.9536\n",
      "Epoch 3/30\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.2761 - acc: 0.9205Epoch 00003: val_loss improved from 0.15942 to 0.15410, saving model to Model_checkpoint_3_0.01_30.hdf5\n",
      "60000/60000 [==============================] - 13s 218us/step - loss: 0.2761 - acc: 0.9206 - val_loss: 0.1541 - val_acc: 0.9537\n",
      "Epoch 4/30\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.2636 - acc: 0.9240Epoch 00004: val_loss did not improve\n",
      "60000/60000 [==============================] - 13s 214us/step - loss: 0.2635 - acc: 0.9241 - val_loss: 0.1574 - val_acc: 0.9551\n",
      "Epoch 5/30\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.2535 - acc: 0.9265Epoch 00005: val_loss improved from 0.15410 to 0.15153, saving model to Model_checkpoint_3_0.01_30.hdf5\n",
      "60000/60000 [==============================] - 12s 200us/step - loss: 0.2535 - acc: 0.9265 - val_loss: 0.1515 - val_acc: 0.9567\n",
      "Epoch 6/30\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.2466 - acc: 0.9288Epoch 00006: val_loss improved from 0.15153 to 0.14722, saving model to Model_checkpoint_3_0.01_30.hdf5\n",
      "60000/60000 [==============================] - 12s 198us/step - loss: 0.2465 - acc: 0.9287 - val_loss: 0.1472 - val_acc: 0.9565\n",
      "Epoch 7/30\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.2401 - acc: 0.9314Epoch 00007: val_loss did not improve\n",
      "60000/60000 [==============================] - 12s 204us/step - loss: 0.2403 - acc: 0.9314 - val_loss: 0.1528 - val_acc: 0.9564\n",
      "Epoch 8/30\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.2364 - acc: 0.9314Epoch 00008: val_loss improved from 0.14722 to 0.12026, saving model to Model_checkpoint_3_0.01_30.hdf5\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 0.2367 - acc: 0.9314 - val_loss: 0.1203 - val_acc: 0.9656\n",
      "Epoch 9/30\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.2330 - acc: 0.9335Epoch 00009: val_loss did not improve\n",
      "60000/60000 [==============================] - 12s 199us/step - loss: 0.2328 - acc: 0.9336 - val_loss: 0.1409 - val_acc: 0.9635\n",
      "Epoch 10/30\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.2337 - acc: 0.9341Epoch 00010: val_loss did not improve\n",
      "60000/60000 [==============================] - 12s 196us/step - loss: 0.2335 - acc: 0.9341 - val_loss: 0.1388 - val_acc: 0.9603\n",
      "Epoch 11/30\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.2360 - acc: 0.9334Epoch 00011: val_loss did not improve\n",
      "60000/60000 [==============================] - 12s 196us/step - loss: 0.2361 - acc: 0.9334 - val_loss: 0.1394 - val_acc: 0.9609\n",
      "Epoch 12/30\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.2323 - acc: 0.9359- ETA: 0s - loss: 0.2325 - acc: Epoch 00012: val_loss did not improve\n",
      "60000/60000 [==============================] - 12s 196us/step - loss: 0.2323 - acc: 0.9358 - val_loss: 0.1294 - val_acc: 0.9633\n",
      "Epoch 13/30\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.2220 - acc: 0.9376Epoch 00013: val_loss did not improve\n",
      "60000/60000 [==============================] - 12s 192us/step - loss: 0.2219 - acc: 0.9376 - val_loss: 0.1385 - val_acc: 0.9621\n",
      "Epoch 14/30\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.2198 - acc: 0.9382Epoch 00014: val_loss did not improve\n",
      "60000/60000 [==============================] - 12s 192us/step - loss: 0.2201 - acc: 0.9381 - val_loss: 0.1249 - val_acc: 0.9664\n",
      "Epoch 15/30\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.2126 - acc: 0.9396Epoch 00015: val_loss did not improve\n",
      "60000/60000 [==============================] - 12s 204us/step - loss: 0.2128 - acc: 0.9395 - val_loss: 0.1238 - val_acc: 0.9665\n",
      "Epoch 16/30\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.2163 - acc: 0.9383Epoch 00016: val_loss did not improve\n",
      "60000/60000 [==============================] - 12s 202us/step - loss: 0.2165 - acc: 0.9382 - val_loss: 0.1302 - val_acc: 0.9630\n",
      "Epoch 17/30\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.2205 - acc: 0.9385Epoch 00017: val_loss did not improve\n",
      "60000/60000 [==============================] - 12s 206us/step - loss: 0.2214 - acc: 0.9384 - val_loss: 0.1316 - val_acc: 0.9644\n",
      "Epoch 18/30\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.2109 - acc: 0.9399Epoch 00018: val_loss did not improve\n",
      "60000/60000 [==============================] - 13s 220us/step - loss: 0.2108 - acc: 0.9400 - val_loss: 0.1209 - val_acc: 0.9652\n",
      "Epoch 19/30\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.2101 - acc: 0.9402Epoch 00019: val_loss did not improve\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 0.2103 - acc: 0.9402 - val_loss: 0.1213 - val_acc: 0.9669\n",
      "Epoch 20/30\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.2095 - acc: 0.9414Epoch 00020: val_loss did not improve\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 0.2096 - acc: 0.9414 - val_loss: 0.1306 - val_acc: 0.9638\n",
      "Epoch 21/30\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.2090 - acc: 0.9408Epoch 00021: val_loss did not improve\n",
      "60000/60000 [==============================] - 13s 210us/step - loss: 0.2090 - acc: 0.9408 - val_loss: 0.1207 - val_acc: 0.9676\n",
      "Epoch 22/30\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.2036 - acc: 0.9426Epoch 00022: val_loss did not improve\n",
      "60000/60000 [==============================] - 12s 202us/step - loss: 0.2034 - acc: 0.9427 - val_loss: 0.1259 - val_acc: 0.9656\n",
      "Epoch 23/30\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.2016 - acc: 0.9427Epoch 00023: val_loss did not improve\n",
      "60000/60000 [==============================] - 13s 210us/step - loss: 0.2016 - acc: 0.9427 - val_loss: 0.1242 - val_acc: 0.9664\n",
      "Epoch 24/30\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.2045 - acc: 0.9421Epoch 00024: val_loss did not improve\n",
      "60000/60000 [==============================] - 12s 206us/step - loss: 0.2045 - acc: 0.9420 - val_loss: 0.1299 - val_acc: 0.9645\n",
      "Epoch 25/30\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.2034 - acc: 0.9433Epoch 00025: val_loss did not improve\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 0.2034 - acc: 0.9433 - val_loss: 0.1290 - val_acc: 0.9659\n",
      "Epoch 26/30\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.2030 - acc: 0.9436Epoch 00026: val_loss improved from 0.12026 to 0.11842, saving model to Model_checkpoint_3_0.01_30.hdf5\n",
      "60000/60000 [==============================] - 12s 202us/step - loss: 0.2033 - acc: 0.9436 - val_loss: 0.1184 - val_acc: 0.9689\n",
      "Epoch 27/30\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.1980 - acc: 0.9443Epoch 00027: val_loss improved from 0.11842 to 0.11142, saving model to Model_checkpoint_3_0.01_30.hdf5\n",
      "60000/60000 [==============================] - 12s 198us/step - loss: 0.1976 - acc: 0.9444 - val_loss: 0.1114 - val_acc: 0.9687\n",
      "Epoch 28/30\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.2018 - acc: 0.9431Epoch 00028: val_loss did not improve\n",
      "60000/60000 [==============================] - 12s 197us/step - loss: 0.2018 - acc: 0.9431 - val_loss: 0.1144 - val_acc: 0.9686\n",
      "Epoch 29/30\n",
      "59648/60000 [============================>.] - ETA: 0s - loss: 0.1978 - acc: 0.9449Epoch 00029: val_loss did not improve\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 0.1974 - acc: 0.9449 - val_loss: 0.1269 - val_acc: 0.9668\n",
      "Epoch 30/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.2026 - acc: 0.9441Epoch 00030: val_loss did not improve\n",
      "60000/60000 [==============================] - 12s 199us/step - loss: 0.2026 - acc: 0.9441 - val_loss: 0.1234 - val_acc: 0.9649\n"
     ]
    }
   ],
   "source": [
    "compile_and_fit_model_Adam(model3,0.01,30,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = Sequential()\n",
    "model4.add(Dense(512, input_shape=(784,)))\n",
    "model4.add(Activation('relu'))\n",
    "model4.add(Dropout(0.5))\n",
    "model4.add(Dense(10))\n",
    "model4.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.3407 - acc: 0.8977Epoch 00001: val_loss improved from inf to 0.17177, saving model to Model_checkpoint_4_0.01_20.hdf5\n",
      "60000/60000 [==============================] - 28s 464us/step - loss: 0.3404 - acc: 0.8977 - val_loss: 0.1718 - val_acc: 0.9493\n",
      "Epoch 2/20\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.2554 - acc: 0.9269- ETA: 1sEpoch 00002: val_loss improved from 0.17177 to 0.14397, saving model to Model_checkpoint_4_0.01_20.hdf5\n",
      "60000/60000 [==============================] - 30s 507us/step - loss: 0.2553 - acc: 0.9268 - val_loss: 0.1440 - val_acc: 0.9618\n",
      "Epoch 3/20\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.2363 - acc: 0.9342Epoch 00003: val_loss did not improve\n",
      "60000/60000 [==============================] - 31s 522us/step - loss: 0.2365 - acc: 0.9341 - val_loss: 0.1458 - val_acc: 0.9601\n",
      "Epoch 4/20\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.2300 - acc: 0.9362Epoch 00004: val_loss improved from 0.14397 to 0.13508, saving model to Model_checkpoint_4_0.01_20.hdf5\n",
      "60000/60000 [==============================] - 32s 537us/step - loss: 0.2302 - acc: 0.9362 - val_loss: 0.1351 - val_acc: 0.9630\n",
      "Epoch 5/20\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.2234 - acc: 0.9397- ETA: - ETA: 7s - loss: 0.220 - ETA: 6s - loss: 0.2Epoch 00005: val_loss did not improve\n",
      "60000/60000 [==============================] - 33s 545us/step - loss: 0.2232 - acc: 0.9397 - val_loss: 0.1483 - val_acc: 0.9622\n",
      "Epoch 6/20\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.2212 - acc: 0.9413- ETA: 0s - loss: 0.2200 - acc:  - ETA: 0s - loss: 0.2211 - acc: 0Epoch 00006: val_loss did not improve\n",
      "60000/60000 [==============================] - 33s 544us/step - loss: 0.2213 - acc: 0.9413 - val_loss: 0.1456 - val_acc: 0.9659\n",
      "Epoch 7/20\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.2161 - acc: 0.9435- ETAEpoch 00007: val_loss did not improve\n",
      "60000/60000 [==============================] - 33s 546us/step - loss: 0.2159 - acc: 0.9435 - val_loss: 0.1402 - val_acc: 0.9660\n",
      "Epoch 8/20\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.2026 - acc: 0.9475- ETA: 6s - loss: 0.2013 - ac - ETA: 6s - loss: 0.20 - ETA - ETA: 2s - loss: 0.2028 - acc: 0.9 -Epoch 00008: val_loss did not improve\n",
      "60000/60000 [==============================] - 33s 553us/step - loss: 0.2025 - acc: 0.9475 - val_loss: 0.1453 - val_acc: 0.9667\n",
      "Epoch 9/20\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.2030 - acc: 0.9482Epoch 00009: val_loss improved from 0.13508 to 0.12835, saving model to Model_checkpoint_4_0.01_20.hdf5\n",
      "60000/60000 [==============================] - 33s 551us/step - loss: 0.2028 - acc: 0.9482 - val_loss: 0.1284 - val_acc: 0.9711\n",
      "Epoch 10/20\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.2018 - acc: 0.9503Epoch 00010: val_loss did not improve\n",
      "60000/60000 [==============================] - 34s 559us/step - loss: 0.2023 - acc: 0.9503 - val_loss: 0.1497 - val_acc: 0.9697\n",
      "Epoch 11/20\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.1965 - acc: 0.9520Epoch 00011: val_loss did not improve\n",
      "60000/60000 [==============================] - 34s 559us/step - loss: 0.1963 - acc: 0.9521 - val_loss: 0.1461 - val_acc: 0.9698\n",
      "Epoch 12/20\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.1986 - acc: 0.9517Epoch 00012: val_loss did not improve\n",
      "60000/60000 [==============================] - 34s 561us/step - loss: 0.1986 - acc: 0.9517 - val_loss: 0.1375 - val_acc: 0.9707\n",
      "Epoch 13/20\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.1942 - acc: 0.9531Epoch 00013: val_loss did not improve\n",
      "60000/60000 [==============================] - 34s 570us/step - loss: 0.1944 - acc: 0.9531 - val_loss: 0.1419 - val_acc: 0.9712\n",
      "Epoch 14/20\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.1878 - acc: 0.9559Epoch 00014: val_loss did not improve\n",
      "60000/60000 [==============================] - 34s 570us/step - loss: 0.1876 - acc: 0.9560 - val_loss: 0.1485 - val_acc: 0.9696\n",
      "Epoch 15/20\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.1906 - acc: 0.9545Epoch 00015: val_loss did not improve\n",
      "60000/60000 [==============================] - 34s 569us/step - loss: 0.1906 - acc: 0.9546 - val_loss: 0.1454 - val_acc: 0.9698\n",
      "Epoch 16/20\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.1916 - acc: 0.9543Epoch 00016: val_loss did not improve\n",
      "60000/60000 [==============================] - 35s 580us/step - loss: 0.1917 - acc: 0.9543 - val_loss: 0.1692 - val_acc: 0.9663\n",
      "Epoch 17/20\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.1776 - acc: 0.9579Epoch 00017: val_loss did not improve\n",
      "60000/60000 [==============================] - 35s 576us/step - loss: 0.1774 - acc: 0.9580 - val_loss: 0.1551 - val_acc: 0.9700\n",
      "Epoch 18/20\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.1862 - acc: 0.9562Epoch 00018: val_loss did not improve\n",
      "60000/60000 [==============================] - 34s 570us/step - loss: 0.1860 - acc: 0.9562 - val_loss: 0.1491 - val_acc: 0.9716\n",
      "Epoch 19/20\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.1853 - acc: 0.9578Epoch 00019: val_loss did not improve\n",
      "60000/60000 [==============================] - 35s 577us/step - loss: 0.1857 - acc: 0.9578 - val_loss: 0.1718 - val_acc: 0.9706\n",
      "Epoch 20/20\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.1915 - acc: 0.9573Epoch 00020: val_loss did not improve\n",
      "60000/60000 [==============================] - 34s 570us/step - loss: 0.1914 - acc: 0.9573 - val_loss: 0.1495 - val_acc: 0.9718\n"
     ]
    }
   ],
   "source": [
    "compile_and_fit_model_Adam(model4,0.01,20,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_lr1 = pd.read_csv('outputs/CSV_logger_2_0.01_30.csv')\n",
    "adam_lr2 = pd.read_csv('outputs/CSV_logger_2_0.001_30.csv')\n",
    "adam_lr3 = pd.read_csv('outputs/CSV_logger_2_0.0001_30.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.960033</td>\n",
       "      <td>0.157414</td>\n",
       "      <td>0.9709</td>\n",
       "      <td>0.178875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.955517</td>\n",
       "      <td>0.174722</td>\n",
       "      <td>0.9703</td>\n",
       "      <td>0.178255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.954367</td>\n",
       "      <td>0.183989</td>\n",
       "      <td>0.9695</td>\n",
       "      <td>0.157341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.953317</td>\n",
       "      <td>0.183213</td>\n",
       "      <td>0.9717</td>\n",
       "      <td>0.177288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.954050</td>\n",
       "      <td>0.184424</td>\n",
       "      <td>0.9699</td>\n",
       "      <td>0.165495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.954000</td>\n",
       "      <td>0.180070</td>\n",
       "      <td>0.9692</td>\n",
       "      <td>0.175506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.954650</td>\n",
       "      <td>0.179011</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.182422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.956817</td>\n",
       "      <td>0.170505</td>\n",
       "      <td>0.9675</td>\n",
       "      <td>0.180848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.955317</td>\n",
       "      <td>0.178202</td>\n",
       "      <td>0.9706</td>\n",
       "      <td>0.178169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.955767</td>\n",
       "      <td>0.173689</td>\n",
       "      <td>0.9718</td>\n",
       "      <td>0.171543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.954900</td>\n",
       "      <td>0.177799</td>\n",
       "      <td>0.9696</td>\n",
       "      <td>0.164858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.956067</td>\n",
       "      <td>0.175292</td>\n",
       "      <td>0.9706</td>\n",
       "      <td>0.167587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.954967</td>\n",
       "      <td>0.177488</td>\n",
       "      <td>0.9701</td>\n",
       "      <td>0.191154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.955050</td>\n",
       "      <td>0.182410</td>\n",
       "      <td>0.9698</td>\n",
       "      <td>0.176399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.955050</td>\n",
       "      <td>0.181006</td>\n",
       "      <td>0.9702</td>\n",
       "      <td>0.196963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.955983</td>\n",
       "      <td>0.179346</td>\n",
       "      <td>0.9713</td>\n",
       "      <td>0.173592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.956800</td>\n",
       "      <td>0.180829</td>\n",
       "      <td>0.9728</td>\n",
       "      <td>0.169063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.958667</td>\n",
       "      <td>0.161503</td>\n",
       "      <td>0.9695</td>\n",
       "      <td>0.183633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.957933</td>\n",
       "      <td>0.176228</td>\n",
       "      <td>0.9696</td>\n",
       "      <td>0.184734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.955267</td>\n",
       "      <td>0.178518</td>\n",
       "      <td>0.9707</td>\n",
       "      <td>0.173281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.956867</td>\n",
       "      <td>0.169927</td>\n",
       "      <td>0.9696</td>\n",
       "      <td>0.188044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0.956617</td>\n",
       "      <td>0.171912</td>\n",
       "      <td>0.9684</td>\n",
       "      <td>0.199416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.956300</td>\n",
       "      <td>0.178675</td>\n",
       "      <td>0.9694</td>\n",
       "      <td>0.195321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0.955833</td>\n",
       "      <td>0.178533</td>\n",
       "      <td>0.9685</td>\n",
       "      <td>0.210421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0.956900</td>\n",
       "      <td>0.176550</td>\n",
       "      <td>0.9685</td>\n",
       "      <td>0.191101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0.955467</td>\n",
       "      <td>0.179106</td>\n",
       "      <td>0.9711</td>\n",
       "      <td>0.190761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0.958450</td>\n",
       "      <td>0.168019</td>\n",
       "      <td>0.9690</td>\n",
       "      <td>0.197035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0.959050</td>\n",
       "      <td>0.169148</td>\n",
       "      <td>0.9698</td>\n",
       "      <td>0.187464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0.958033</td>\n",
       "      <td>0.169664</td>\n",
       "      <td>0.9719</td>\n",
       "      <td>0.175945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0.958200</td>\n",
       "      <td>0.169554</td>\n",
       "      <td>0.9687</td>\n",
       "      <td>0.195617</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch       acc      loss  val_acc  val_loss\n",
       "0       0  0.960033  0.157414   0.9709  0.178875\n",
       "1       1  0.955517  0.174722   0.9703  0.178255\n",
       "2       2  0.954367  0.183989   0.9695  0.157341\n",
       "3       3  0.953317  0.183213   0.9717  0.177288\n",
       "4       4  0.954050  0.184424   0.9699  0.165495\n",
       "5       5  0.954000  0.180070   0.9692  0.175506\n",
       "6       6  0.954650  0.179011   0.9700  0.182422\n",
       "7       7  0.956817  0.170505   0.9675  0.180848\n",
       "8       8  0.955317  0.178202   0.9706  0.178169\n",
       "9       9  0.955767  0.173689   0.9718  0.171543\n",
       "10     10  0.954900  0.177799   0.9696  0.164858\n",
       "11     11  0.956067  0.175292   0.9706  0.167587\n",
       "12     12  0.954967  0.177488   0.9701  0.191154\n",
       "13     13  0.955050  0.182410   0.9698  0.176399\n",
       "14     14  0.955050  0.181006   0.9702  0.196963\n",
       "15     15  0.955983  0.179346   0.9713  0.173592\n",
       "16     16  0.956800  0.180829   0.9728  0.169063\n",
       "17     17  0.958667  0.161503   0.9695  0.183633\n",
       "18     18  0.957933  0.176228   0.9696  0.184734\n",
       "19     19  0.955267  0.178518   0.9707  0.173281\n",
       "20     20  0.956867  0.169927   0.9696  0.188044\n",
       "21     21  0.956617  0.171912   0.9684  0.199416\n",
       "22     22  0.956300  0.178675   0.9694  0.195321\n",
       "23     23  0.955833  0.178533   0.9685  0.210421\n",
       "24     24  0.956900  0.176550   0.9685  0.191101\n",
       "25     25  0.955467  0.179106   0.9711  0.190761\n",
       "26     26  0.958450  0.168019   0.9690  0.197035\n",
       "27     27  0.959050  0.169148   0.9698  0.187464\n",
       "28     28  0.958033  0.169664   0.9719  0.175945\n",
       "29     29  0.958200  0.169554   0.9687  0.195617"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adam_lr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.960433</td>\n",
       "      <td>0.145944</td>\n",
       "      <td>0.9748</td>\n",
       "      <td>0.131113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.963667</td>\n",
       "      <td>0.124257</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.129240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.966783</td>\n",
       "      <td>0.116588</td>\n",
       "      <td>0.9744</td>\n",
       "      <td>0.129036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.968467</td>\n",
       "      <td>0.109557</td>\n",
       "      <td>0.9744</td>\n",
       "      <td>0.128677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.967633</td>\n",
       "      <td>0.108167</td>\n",
       "      <td>0.9752</td>\n",
       "      <td>0.127435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.969250</td>\n",
       "      <td>0.104220</td>\n",
       "      <td>0.9756</td>\n",
       "      <td>0.124386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.969950</td>\n",
       "      <td>0.100432</td>\n",
       "      <td>0.9767</td>\n",
       "      <td>0.125679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.970717</td>\n",
       "      <td>0.098480</td>\n",
       "      <td>0.9759</td>\n",
       "      <td>0.123227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.970450</td>\n",
       "      <td>0.097047</td>\n",
       "      <td>0.9755</td>\n",
       "      <td>0.124225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.970433</td>\n",
       "      <td>0.094821</td>\n",
       "      <td>0.9770</td>\n",
       "      <td>0.124295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.971800</td>\n",
       "      <td>0.094645</td>\n",
       "      <td>0.9765</td>\n",
       "      <td>0.121589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.971783</td>\n",
       "      <td>0.094020</td>\n",
       "      <td>0.9758</td>\n",
       "      <td>0.122794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.972167</td>\n",
       "      <td>0.091797</td>\n",
       "      <td>0.9751</td>\n",
       "      <td>0.122772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.973050</td>\n",
       "      <td>0.089731</td>\n",
       "      <td>0.9767</td>\n",
       "      <td>0.121591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.972917</td>\n",
       "      <td>0.087966</td>\n",
       "      <td>0.9757</td>\n",
       "      <td>0.120573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.972883</td>\n",
       "      <td>0.089597</td>\n",
       "      <td>0.9752</td>\n",
       "      <td>0.125995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.972933</td>\n",
       "      <td>0.089304</td>\n",
       "      <td>0.9756</td>\n",
       "      <td>0.121803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.973617</td>\n",
       "      <td>0.083422</td>\n",
       "      <td>0.9757</td>\n",
       "      <td>0.124001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.974017</td>\n",
       "      <td>0.082900</td>\n",
       "      <td>0.9771</td>\n",
       "      <td>0.122373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.973750</td>\n",
       "      <td>0.084713</td>\n",
       "      <td>0.9762</td>\n",
       "      <td>0.123148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.974167</td>\n",
       "      <td>0.085546</td>\n",
       "      <td>0.9762</td>\n",
       "      <td>0.121736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0.975267</td>\n",
       "      <td>0.080924</td>\n",
       "      <td>0.9769</td>\n",
       "      <td>0.122621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.974183</td>\n",
       "      <td>0.083744</td>\n",
       "      <td>0.9760</td>\n",
       "      <td>0.123183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0.975650</td>\n",
       "      <td>0.078504</td>\n",
       "      <td>0.9756</td>\n",
       "      <td>0.123858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0.974750</td>\n",
       "      <td>0.081325</td>\n",
       "      <td>0.9758</td>\n",
       "      <td>0.124148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0.974267</td>\n",
       "      <td>0.081836</td>\n",
       "      <td>0.9763</td>\n",
       "      <td>0.124999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0.975933</td>\n",
       "      <td>0.078296</td>\n",
       "      <td>0.9760</td>\n",
       "      <td>0.125153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0.975617</td>\n",
       "      <td>0.080745</td>\n",
       "      <td>0.9755</td>\n",
       "      <td>0.123351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0.975267</td>\n",
       "      <td>0.078138</td>\n",
       "      <td>0.9752</td>\n",
       "      <td>0.128908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0.976383</td>\n",
       "      <td>0.077248</td>\n",
       "      <td>0.9758</td>\n",
       "      <td>0.128146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch       acc      loss  val_acc  val_loss\n",
       "0       0  0.960433  0.145944   0.9748  0.131113\n",
       "1       1  0.963667  0.124257   0.9739  0.129240\n",
       "2       2  0.966783  0.116588   0.9744  0.129036\n",
       "3       3  0.968467  0.109557   0.9744  0.128677\n",
       "4       4  0.967633  0.108167   0.9752  0.127435\n",
       "5       5  0.969250  0.104220   0.9756  0.124386\n",
       "6       6  0.969950  0.100432   0.9767  0.125679\n",
       "7       7  0.970717  0.098480   0.9759  0.123227\n",
       "8       8  0.970450  0.097047   0.9755  0.124225\n",
       "9       9  0.970433  0.094821   0.9770  0.124295\n",
       "10     10  0.971800  0.094645   0.9765  0.121589\n",
       "11     11  0.971783  0.094020   0.9758  0.122794\n",
       "12     12  0.972167  0.091797   0.9751  0.122772\n",
       "13     13  0.973050  0.089731   0.9767  0.121591\n",
       "14     14  0.972917  0.087966   0.9757  0.120573\n",
       "15     15  0.972883  0.089597   0.9752  0.125995\n",
       "16     16  0.972933  0.089304   0.9756  0.121803\n",
       "17     17  0.973617  0.083422   0.9757  0.124001\n",
       "18     18  0.974017  0.082900   0.9771  0.122373\n",
       "19     19  0.973750  0.084713   0.9762  0.123148\n",
       "20     20  0.974167  0.085546   0.9762  0.121736\n",
       "21     21  0.975267  0.080924   0.9769  0.122621\n",
       "22     22  0.974183  0.083744   0.9760  0.123183\n",
       "23     23  0.975650  0.078504   0.9756  0.123858\n",
       "24     24  0.974750  0.081325   0.9758  0.124148\n",
       "25     25  0.974267  0.081836   0.9763  0.124999\n",
       "26     26  0.975933  0.078296   0.9760  0.125153\n",
       "27     27  0.975617  0.080745   0.9755  0.123351\n",
       "28     28  0.975267  0.078138   0.9752  0.128908\n",
       "29     29  0.976383  0.077248   0.9758  0.128146"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adam_lr2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.976717</td>\n",
       "      <td>0.076481</td>\n",
       "      <td>0.9761</td>\n",
       "      <td>0.128362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.977083</td>\n",
       "      <td>0.074820</td>\n",
       "      <td>0.9760</td>\n",
       "      <td>0.128095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.977550</td>\n",
       "      <td>0.073531</td>\n",
       "      <td>0.9760</td>\n",
       "      <td>0.128393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.978533</td>\n",
       "      <td>0.070685</td>\n",
       "      <td>0.9758</td>\n",
       "      <td>0.128015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.977150</td>\n",
       "      <td>0.073345</td>\n",
       "      <td>0.9756</td>\n",
       "      <td>0.128386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.978067</td>\n",
       "      <td>0.071485</td>\n",
       "      <td>0.9756</td>\n",
       "      <td>0.128270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.978417</td>\n",
       "      <td>0.070200</td>\n",
       "      <td>0.9757</td>\n",
       "      <td>0.127727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.978650</td>\n",
       "      <td>0.070323</td>\n",
       "      <td>0.9756</td>\n",
       "      <td>0.127691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.977600</td>\n",
       "      <td>0.070771</td>\n",
       "      <td>0.9757</td>\n",
       "      <td>0.127508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.977733</td>\n",
       "      <td>0.071063</td>\n",
       "      <td>0.9758</td>\n",
       "      <td>0.127360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.977633</td>\n",
       "      <td>0.070646</td>\n",
       "      <td>0.9758</td>\n",
       "      <td>0.127755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.978300</td>\n",
       "      <td>0.070335</td>\n",
       "      <td>0.9758</td>\n",
       "      <td>0.127485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.978100</td>\n",
       "      <td>0.071466</td>\n",
       "      <td>0.9758</td>\n",
       "      <td>0.127734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.978367</td>\n",
       "      <td>0.068827</td>\n",
       "      <td>0.9758</td>\n",
       "      <td>0.127827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.977250</td>\n",
       "      <td>0.072404</td>\n",
       "      <td>0.9755</td>\n",
       "      <td>0.128255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.978350</td>\n",
       "      <td>0.071193</td>\n",
       "      <td>0.9756</td>\n",
       "      <td>0.128081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.979333</td>\n",
       "      <td>0.067699</td>\n",
       "      <td>0.9757</td>\n",
       "      <td>0.127878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.978317</td>\n",
       "      <td>0.069822</td>\n",
       "      <td>0.9756</td>\n",
       "      <td>0.128643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.978200</td>\n",
       "      <td>0.068429</td>\n",
       "      <td>0.9758</td>\n",
       "      <td>0.129188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.978767</td>\n",
       "      <td>0.068914</td>\n",
       "      <td>0.9755</td>\n",
       "      <td>0.129061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0.978733</td>\n",
       "      <td>0.068834</td>\n",
       "      <td>0.9757</td>\n",
       "      <td>0.129553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0.977683</td>\n",
       "      <td>0.069252</td>\n",
       "      <td>0.9754</td>\n",
       "      <td>0.129574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>0.979300</td>\n",
       "      <td>0.065513</td>\n",
       "      <td>0.9757</td>\n",
       "      <td>0.129241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0.978583</td>\n",
       "      <td>0.068870</td>\n",
       "      <td>0.9755</td>\n",
       "      <td>0.130078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>0.978283</td>\n",
       "      <td>0.070039</td>\n",
       "      <td>0.9753</td>\n",
       "      <td>0.128837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0.978633</td>\n",
       "      <td>0.067790</td>\n",
       "      <td>0.9757</td>\n",
       "      <td>0.128584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>0.978467</td>\n",
       "      <td>0.070220</td>\n",
       "      <td>0.9758</td>\n",
       "      <td>0.128369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0.978150</td>\n",
       "      <td>0.070551</td>\n",
       "      <td>0.9759</td>\n",
       "      <td>0.129308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0.978583</td>\n",
       "      <td>0.066722</td>\n",
       "      <td>0.9754</td>\n",
       "      <td>0.130206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>0.977783</td>\n",
       "      <td>0.071665</td>\n",
       "      <td>0.9757</td>\n",
       "      <td>0.129910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch       acc      loss  val_acc  val_loss\n",
       "0       0  0.976717  0.076481   0.9761  0.128362\n",
       "1       1  0.977083  0.074820   0.9760  0.128095\n",
       "2       2  0.977550  0.073531   0.9760  0.128393\n",
       "3       3  0.978533  0.070685   0.9758  0.128015\n",
       "4       4  0.977150  0.073345   0.9756  0.128386\n",
       "5       5  0.978067  0.071485   0.9756  0.128270\n",
       "6       6  0.978417  0.070200   0.9757  0.127727\n",
       "7       7  0.978650  0.070323   0.9756  0.127691\n",
       "8       8  0.977600  0.070771   0.9757  0.127508\n",
       "9       9  0.977733  0.071063   0.9758  0.127360\n",
       "10     10  0.977633  0.070646   0.9758  0.127755\n",
       "11     11  0.978300  0.070335   0.9758  0.127485\n",
       "12     12  0.978100  0.071466   0.9758  0.127734\n",
       "13     13  0.978367  0.068827   0.9758  0.127827\n",
       "14     14  0.977250  0.072404   0.9755  0.128255\n",
       "15     15  0.978350  0.071193   0.9756  0.128081\n",
       "16     16  0.979333  0.067699   0.9757  0.127878\n",
       "17     17  0.978317  0.069822   0.9756  0.128643\n",
       "18     18  0.978200  0.068429   0.9758  0.129188\n",
       "19     19  0.978767  0.068914   0.9755  0.129061\n",
       "20     20  0.978733  0.068834   0.9757  0.129553\n",
       "21     21  0.977683  0.069252   0.9754  0.129574\n",
       "22     22  0.979300  0.065513   0.9757  0.129241\n",
       "23     23  0.978583  0.068870   0.9755  0.130078\n",
       "24     24  0.978283  0.070039   0.9753  0.128837\n",
       "25     25  0.978633  0.067790   0.9757  0.128584\n",
       "26     26  0.978467  0.070220   0.9758  0.128369\n",
       "27     27  0.978150  0.070551   0.9759  0.129308\n",
       "28     28  0.978583  0.066722   0.9754  0.130206\n",
       "29     29  0.977783  0.071665   0.9757  0.129910"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adam_lr3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Adam optimiser with varying learning rates')\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.ylabel('Validation accuracy')\n",
    "plt.plot(adam_lr1['epoch'],adam_lr1['val_acc'],color='red',label='lr0.01')\n",
    "plt.plot(adam_lr2['epoch'],adam_lr2['val_acc'],color='green',label='lr0.001')\n",
    "plt.plot(adam_lr3['epoch'],adam_lr3['val_acc'],color='blue',label='lr0.0001')\n",
    "plt.savefig('plots/Adam optimiser with varying learning rates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f098edab5d0>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEZCAYAAABSN8jfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f098ec9a390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The best results have been obtained with the model of \n",
    "#learning rate 0.001 and Adam optimiser for hidden layer consisting of 128 neurons\n",
    "#and with 'relu' as activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_196 = pd.read_csv('outputs/CSV_logger_1_0.01_20.csv')\n",
    "adam_128 = pd.read_csv('outputs/CSV_logger_2_0.01_20.csv')\n",
    "adam_512 = pd.read_csv('outputs/CSV_logger_4_0.01_20.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.880433</td>\n",
       "      <td>0.389672</td>\n",
       "      <td>0.9489</td>\n",
       "      <td>0.170094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.911233</td>\n",
       "      <td>0.289396</td>\n",
       "      <td>0.9579</td>\n",
       "      <td>0.149883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.921967</td>\n",
       "      <td>0.259087</td>\n",
       "      <td>0.9589</td>\n",
       "      <td>0.147705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.927617</td>\n",
       "      <td>0.243821</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>0.128211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.931483</td>\n",
       "      <td>0.235279</td>\n",
       "      <td>0.9647</td>\n",
       "      <td>0.135705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.930633</td>\n",
       "      <td>0.233484</td>\n",
       "      <td>0.9653</td>\n",
       "      <td>0.138228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.932683</td>\n",
       "      <td>0.231652</td>\n",
       "      <td>0.9677</td>\n",
       "      <td>0.122201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.935967</td>\n",
       "      <td>0.221198</td>\n",
       "      <td>0.9681</td>\n",
       "      <td>0.133654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.217699</td>\n",
       "      <td>0.9646</td>\n",
       "      <td>0.134271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.937550</td>\n",
       "      <td>0.218446</td>\n",
       "      <td>0.9657</td>\n",
       "      <td>0.138756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.938283</td>\n",
       "      <td>0.219159</td>\n",
       "      <td>0.9680</td>\n",
       "      <td>0.132231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.940700</td>\n",
       "      <td>0.208564</td>\n",
       "      <td>0.9689</td>\n",
       "      <td>0.139861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.941117</td>\n",
       "      <td>0.207712</td>\n",
       "      <td>0.9659</td>\n",
       "      <td>0.145661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.943417</td>\n",
       "      <td>0.202816</td>\n",
       "      <td>0.9679</td>\n",
       "      <td>0.149713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.942917</td>\n",
       "      <td>0.208372</td>\n",
       "      <td>0.9685</td>\n",
       "      <td>0.130569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.945050</td>\n",
       "      <td>0.199834</td>\n",
       "      <td>0.9703</td>\n",
       "      <td>0.137798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.945283</td>\n",
       "      <td>0.199841</td>\n",
       "      <td>0.9707</td>\n",
       "      <td>0.140547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.944050</td>\n",
       "      <td>0.203331</td>\n",
       "      <td>0.9698</td>\n",
       "      <td>0.142046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.946417</td>\n",
       "      <td>0.194914</td>\n",
       "      <td>0.9695</td>\n",
       "      <td>0.143812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.945267</td>\n",
       "      <td>0.194675</td>\n",
       "      <td>0.9704</td>\n",
       "      <td>0.143754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch       acc      loss  val_acc  val_loss\n",
       "0       0  0.880433  0.389672   0.9489  0.170094\n",
       "1       1  0.911233  0.289396   0.9579  0.149883\n",
       "2       2  0.921967  0.259087   0.9589  0.147705\n",
       "3       3  0.927617  0.243821   0.9643  0.128211\n",
       "4       4  0.931483  0.235279   0.9647  0.135705\n",
       "5       5  0.930633  0.233484   0.9653  0.138228\n",
       "6       6  0.932683  0.231652   0.9677  0.122201\n",
       "7       7  0.935967  0.221198   0.9681  0.133654\n",
       "8       8  0.937500  0.217699   0.9646  0.134271\n",
       "9       9  0.937550  0.218446   0.9657  0.138756\n",
       "10     10  0.938283  0.219159   0.9680  0.132231\n",
       "11     11  0.940700  0.208564   0.9689  0.139861\n",
       "12     12  0.941117  0.207712   0.9659  0.145661\n",
       "13     13  0.943417  0.202816   0.9679  0.149713\n",
       "14     14  0.942917  0.208372   0.9685  0.130569\n",
       "15     15  0.945050  0.199834   0.9703  0.137798\n",
       "16     16  0.945283  0.199841   0.9707  0.140547\n",
       "17     17  0.944050  0.203331   0.9698  0.142046\n",
       "18     18  0.946417  0.194914   0.9695  0.143812\n",
       "19     19  0.945267  0.194675   0.9704  0.143754"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adam_128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.889567</td>\n",
       "      <td>0.362763</td>\n",
       "      <td>0.9528</td>\n",
       "      <td>0.150562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.920767</td>\n",
       "      <td>0.268806</td>\n",
       "      <td>0.9584</td>\n",
       "      <td>0.137198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.926200</td>\n",
       "      <td>0.250767</td>\n",
       "      <td>0.9657</td>\n",
       "      <td>0.121131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.931717</td>\n",
       "      <td>0.236031</td>\n",
       "      <td>0.9650</td>\n",
       "      <td>0.130071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.935017</td>\n",
       "      <td>0.227379</td>\n",
       "      <td>0.9646</td>\n",
       "      <td>0.130407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.938883</td>\n",
       "      <td>0.213819</td>\n",
       "      <td>0.9661</td>\n",
       "      <td>0.129502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.941967</td>\n",
       "      <td>0.207980</td>\n",
       "      <td>0.9667</td>\n",
       "      <td>0.131630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.941617</td>\n",
       "      <td>0.209417</td>\n",
       "      <td>0.9686</td>\n",
       "      <td>0.128560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.943900</td>\n",
       "      <td>0.204813</td>\n",
       "      <td>0.9688</td>\n",
       "      <td>0.134354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.945067</td>\n",
       "      <td>0.204259</td>\n",
       "      <td>0.9691</td>\n",
       "      <td>0.131877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.946283</td>\n",
       "      <td>0.198319</td>\n",
       "      <td>0.9685</td>\n",
       "      <td>0.129182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.946417</td>\n",
       "      <td>0.197814</td>\n",
       "      <td>0.9718</td>\n",
       "      <td>0.136133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.945817</td>\n",
       "      <td>0.199432</td>\n",
       "      <td>0.9703</td>\n",
       "      <td>0.138189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.946667</td>\n",
       "      <td>0.201796</td>\n",
       "      <td>0.9726</td>\n",
       "      <td>0.134267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.949867</td>\n",
       "      <td>0.186691</td>\n",
       "      <td>0.9709</td>\n",
       "      <td>0.141236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.947733</td>\n",
       "      <td>0.195882</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>0.154272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.949067</td>\n",
       "      <td>0.193725</td>\n",
       "      <td>0.9686</td>\n",
       "      <td>0.151163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.951500</td>\n",
       "      <td>0.185097</td>\n",
       "      <td>0.9693</td>\n",
       "      <td>0.156419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.950483</td>\n",
       "      <td>0.189643</td>\n",
       "      <td>0.9696</td>\n",
       "      <td>0.144497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.951133</td>\n",
       "      <td>0.186033</td>\n",
       "      <td>0.9701</td>\n",
       "      <td>0.154938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch       acc      loss  val_acc  val_loss\n",
       "0       0  0.889567  0.362763   0.9528  0.150562\n",
       "1       1  0.920767  0.268806   0.9584  0.137198\n",
       "2       2  0.926200  0.250767   0.9657  0.121131\n",
       "3       3  0.931717  0.236031   0.9650  0.130071\n",
       "4       4  0.935017  0.227379   0.9646  0.130407\n",
       "5       5  0.938883  0.213819   0.9661  0.129502\n",
       "6       6  0.941967  0.207980   0.9667  0.131630\n",
       "7       7  0.941617  0.209417   0.9686  0.128560\n",
       "8       8  0.943900  0.204813   0.9688  0.134354\n",
       "9       9  0.945067  0.204259   0.9691  0.131877\n",
       "10     10  0.946283  0.198319   0.9685  0.129182\n",
       "11     11  0.946417  0.197814   0.9718  0.136133\n",
       "12     12  0.945817  0.199432   0.9703  0.138189\n",
       "13     13  0.946667  0.201796   0.9726  0.134267\n",
       "14     14  0.949867  0.186691   0.9709  0.141236\n",
       "15     15  0.947733  0.195882   0.9673  0.154272\n",
       "16     16  0.949067  0.193725   0.9686  0.151163\n",
       "17     17  0.951500  0.185097   0.9693  0.156419\n",
       "18     18  0.950483  0.189643   0.9696  0.144497\n",
       "19     19  0.951133  0.186033   0.9701  0.154938"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adam_196"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.897733</td>\n",
       "      <td>0.340430</td>\n",
       "      <td>0.9493</td>\n",
       "      <td>0.171774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.926833</td>\n",
       "      <td>0.255321</td>\n",
       "      <td>0.9618</td>\n",
       "      <td>0.143969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.934133</td>\n",
       "      <td>0.236505</td>\n",
       "      <td>0.9601</td>\n",
       "      <td>0.145815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.936183</td>\n",
       "      <td>0.230185</td>\n",
       "      <td>0.9630</td>\n",
       "      <td>0.135080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.939683</td>\n",
       "      <td>0.223203</td>\n",
       "      <td>0.9622</td>\n",
       "      <td>0.148276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>0.941333</td>\n",
       "      <td>0.221348</td>\n",
       "      <td>0.9659</td>\n",
       "      <td>0.145613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0.943533</td>\n",
       "      <td>0.215893</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>0.140152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0.947517</td>\n",
       "      <td>0.202511</td>\n",
       "      <td>0.9667</td>\n",
       "      <td>0.145344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0.948217</td>\n",
       "      <td>0.202789</td>\n",
       "      <td>0.9711</td>\n",
       "      <td>0.128353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.950267</td>\n",
       "      <td>0.202250</td>\n",
       "      <td>0.9697</td>\n",
       "      <td>0.149729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.952050</td>\n",
       "      <td>0.196342</td>\n",
       "      <td>0.9698</td>\n",
       "      <td>0.146092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>0.951683</td>\n",
       "      <td>0.198603</td>\n",
       "      <td>0.9707</td>\n",
       "      <td>0.137525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0.953117</td>\n",
       "      <td>0.194402</td>\n",
       "      <td>0.9712</td>\n",
       "      <td>0.141938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.956000</td>\n",
       "      <td>0.187632</td>\n",
       "      <td>0.9696</td>\n",
       "      <td>0.148473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>0.954567</td>\n",
       "      <td>0.190567</td>\n",
       "      <td>0.9698</td>\n",
       "      <td>0.145398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>0.954300</td>\n",
       "      <td>0.191727</td>\n",
       "      <td>0.9663</td>\n",
       "      <td>0.169193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0.957983</td>\n",
       "      <td>0.177388</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.155127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>0.956200</td>\n",
       "      <td>0.186005</td>\n",
       "      <td>0.9716</td>\n",
       "      <td>0.149113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>0.957800</td>\n",
       "      <td>0.185652</td>\n",
       "      <td>0.9706</td>\n",
       "      <td>0.171787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0.957267</td>\n",
       "      <td>0.191437</td>\n",
       "      <td>0.9718</td>\n",
       "      <td>0.149513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    epoch       acc      loss  val_acc  val_loss\n",
       "0       0  0.897733  0.340430   0.9493  0.171774\n",
       "1       1  0.926833  0.255321   0.9618  0.143969\n",
       "2       2  0.934133  0.236505   0.9601  0.145815\n",
       "3       3  0.936183  0.230185   0.9630  0.135080\n",
       "4       4  0.939683  0.223203   0.9622  0.148276\n",
       "5       5  0.941333  0.221348   0.9659  0.145613\n",
       "6       6  0.943533  0.215893   0.9660  0.140152\n",
       "7       7  0.947517  0.202511   0.9667  0.145344\n",
       "8       8  0.948217  0.202789   0.9711  0.128353\n",
       "9       9  0.950267  0.202250   0.9697  0.149729\n",
       "10     10  0.952050  0.196342   0.9698  0.146092\n",
       "11     11  0.951683  0.198603   0.9707  0.137525\n",
       "12     12  0.953117  0.194402   0.9712  0.141938\n",
       "13     13  0.956000  0.187632   0.9696  0.148473\n",
       "14     14  0.954567  0.190567   0.9698  0.145398\n",
       "15     15  0.954300  0.191727   0.9663  0.169193\n",
       "16     16  0.957983  0.177388   0.9700  0.155127\n",
       "17     17  0.956200  0.186005   0.9716  0.149113\n",
       "18     18  0.957800  0.185652   0.9706  0.171787\n",
       "19     19  0.957267  0.191437   0.9718  0.149513"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adam_512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Adam optimiser with varying number of neurons in hidden layer')\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.ylabel('Validation accuracy')\n",
    "plt.plot(adam_128['epoch'],adam_128['val_acc'],color='red',label='128')\n",
    "plt.plot(adam_196['epoch'],adam_196['val_acc'],color='green',label='196')\n",
    "plt.plot(adam_512['epoch'],adam_512['val_acc'],color='blue',label='512')\n",
    "plt.savefig('plots/Adam optimiser with varying number of neurons in hidden layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f0991fe7dd0>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAacAAAEZCAYAAAAzL+qdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmZkVjsPJzMwKx+FkZmaF81tLeQUjnsbwnQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0991c71310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam_128 = pd.read_csv('outputs/CSV_logger_2_0.01_20.csv')\n",
    "sgd_128 = pd.read_csv('outputs/CSV_logger_SGD_2_0.01_20.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Varying optimisers with 128 neurons')\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.ylabel('Validation accuracy')\n",
    "plt.plot(adam_128['epoch'],adam_128['val_acc'],color='red',label='Adam')\n",
    "plt.plot(sgd_128['epoch'],sgd_128['val_acc'],color='green',label='SGD')\n",
    "plt.savefig('plots/Varying optimisers with 128 neurons')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f0991c6ac90>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEZCAYAAABSN8jfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGBM1SybGGGOiZsnEGGNM1P4f83gEGxNn9NwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f098f67d310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_196 = pd.read_csv('CSV_logger_1_0.01_20.csv')\n",
    "tanh_196 = pd.read_csv('CSV_logger_3_0.01_30.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZMAAAEZCAYAAABSN8jfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nw5xMzMysYU4mZmbWsL8BLmiG6dBOfJUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f09973faf50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Varying activations with 196 neurons')\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.ylabel('Validation accuracy')\n",
    "plt.plot(relu_196['epoch'],relu_196['val_acc'],color='red',label='Relu')\n",
    "plt.plot(tanh_196[:20]['epoch'],tanh_196[:20]['val_acc'],color='green',label='Tanh')\n",
    "plt.savefig('plots/Varying activations with 196 neurons')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hence the best set of hyperparameters will be SGD optimiser with 128 neurons \n",
    "#and learning rate = 0.001 and Relu activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.read_csv('outputs/CSV_logger_SGD_2_0.001_20.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZkAAAEZCAYAAABFFVgWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xu8VXWd//HXG9FKQCUUAY+AV1AUUchbXrZWo6WjJWrS\nzKTVlFNqNZaX5lcjVo6WmVOZU3nL0jIbJzXTMMVjKl5QxBsgqIgoChop3vDC+fz++K4Ni8W+rL33\nWvtyzuf5eOzHOXvttdda+8A537XW5/t9f2VmOOecc3no1+oDcM4513t5I+Occy433sg455zLjTcy\nzjnncuONjHPOudx4I+Occy433sg4lzNJ20uaJWmFpHcl/b8MtjlKUo8k/x12ba1/qw/AuT7gVOA2\nM9st4+36IDfX9vwsyLn8jQIea/VBONcK3sg4lyNJtwIHABdEt8uulPTt6LX9JS2WdLKkpZKek3Rc\n7L0fi26zvSJpkaQzWvQxnKubNzLO5cjMPgTcAZxgZhsBbydWGQYMAkYA/wr8VNLG0WuvAf9iZhsD\nhwD/Jumw5hy5c9nwRsa55lCZ5W8D3zGzVWZ2E6FhGQNgZn81s8ei7x8FrgL2b8bBOpcVb2Sca62/\nmVlP7PkbwEAASXtImi5pmaSXgeOBTVtxkM7VyxsZ59rXlcC1wBZmtgnwc8pfETnXlryRca59DQT+\nbmbvSNod+FTidW9wXNvzRsa5/NUyniW+7peA70h6Bfgm8LsGtutcSyjvScskHQz8N6FBu8TMvpd4\nfSRwKbAZ8Dfgn81siaQCcD7hF0nAWOCTZna9pMsIBdBXotePM7OHJX0KOC1a9hrwRTN7JNcP6Jxz\nrqxcG5ko8mI+8CFgCTATOMbM5sXWuRq43syuiBqWz5rZpxPbGQwsINybfitqZK43sz8k1tsTmGtm\nr0SN21Qz2zO3D+icc66ivG+X7Q4sMLNFZvYOoQvm4Yl1dgSmA5hZd4nXAY4EbjKzt2LL1jl2M7vH\nzF6Jnt4DbNHY4TvnnGtE3o3MFsDi2PNnWfcP/2xgMoCkI4CB0ZVL3DHAbxPLvitptqTzJK1fYt//\nCtxU95E755xrWN6NTKneL8n7c6cABUkPAPsCzwHvrt6ANAzYCZgWe8/pZrYD8AFgCKEOQ+w9BwCf\nSS53zjnXXHmnMD8LjIw97yLUZlYzs+dZcyUzAJhsZq/GVjka+IOZrYq9Z2n09Z2oPvO14muSxgO/\nAA42s7+XOihJ3ivHOefqYGY1dZ3P+0pmJrBtNPfFBoTbXtfHV5A0RFLxoL9B6GkWN4XErbLo6obo\nfR8HHo2ejwSuIeQ9PVnpwMzMHxk9zjjjjJYfQ296tPTnOWoUttNOGGBvvdXyn0VH/yx74aMeuTYy\nFq4+TgRuJkSdX2VmcyWdKenQaLUC8LikecBQ4Kzi+yWNArrM7PbEpq+U9BDwEOF22Xej5d8C3g9c\nKOlBSffl9NGc633++7/h2Wfh1lth/fXhJi9pusblPmmZmf2ZKPAvtuyM2PfXEK4+Sr13EbBlieUf\nKrP+54HPN3K8zvVJb7wBp58OJ58MQ4fC8OHwpz/B4aU6ezqXno/4dw0rFAqtPoRepSU/zylTYOBA\nOOec8HznneG+zr8R4P83Wy/3Ef/tSJL1xc/tXEmzZsGkSeH22EEHhWU//CFMnQorVrT00Fx7kYTV\nWPj3Rsa5vm70aBgxAmbMWLPsmWdg1Ch46y3YYIOWHZprL/U0Mn67zLm+rFjsv/batZePHOnFf5cJ\nb2Sc66uSxf6kYvHfuQZ4I+NcX5Us9if1kuK/ay1vZJzri2bNgj/+Ea68EvqV+TNw4IHw1FPNPS7X\n63jh37m+qFSxP8mL/y7BC//OuerKFfuTvPjvMuCNjOt8jz4aagsrV7b6SNpftWJ/khf/W+/ss+G9\n74UFC1p9JHXxRsZ1vptvhtdfh//6r1YfSfurVuxP8uJ/6/T0wFFHwTe/GW5Xnnpqq4+oLt7IuM73\n8MPh689/3trjaHdpiv1JXvxvjTfeCA38H/8YAkvPOgtuvDE0PB3GC/+u833wg7BqVTjjvvtu2GOP\nVh9Re0pT7E/y4n/zPfkkfOAD0L9/ODHo6gqNy/veB+edByee2LJD88K/65sWL4bddoOddgr1Breu\ntMX+JC/+N9eNN8IOO8DWW4d/r66usLxfP/joR0OmXIfxRsZ1vuXLYcKEcO/6jju8A0BSrcX+JC/+\nN8fZZ8Ohh8KnPgX337/uleO558LChR3XAcAbGdf53ngD9t4bjj469MLxDgBrq7XYn+TF/3zFC/w/\n+hH88pel19tuu3DLs8M6AHgj4zrbM8+AGey4Y3h+9NHeASCunmJ/khf/85Ms8J90UuX1Tz654zoA\neOHfdbbf/Q6OPXbNLbJly2DYMO8AUFRPsT/Ji//5KFXgr6bFHQC88O/6ngcegMGD1zwfOtQ7ABTV\nW+xP8uJ/9m66qXSBv5oO7ACQeyMj6WBJ8yTNl3RaiddHSrpF0kOSpksaES0vSHpQ0qzo65uSDote\nu0zSU7HXx8e292NJCyTNljQh78/nWmzOnFCYjvMOAI0X+5O8+J+dc86BQw6Bf/qn0gX+ajqtA4CZ\n5fYgNGJPAKOA9YHZwNjEOlcD/xx9XwB+VWI7g4GXgPdEzy8DPlFivY8Cf4q+3wO4p8xxmesldtzR\nbPLkdZcPGGD2rW81/3jaxWGHmQ0ZYrZqVTbbO+QQs112yWZbfdlRR5n162f24x83tp3Ro80+/vFs\njqkG0d/OmtqBvK9kdgcWmNkiM3sHuAo4PLHOjsD06C9/d4nXAY4EbjKzt2LLSh374cCvom3dC2ws\nafOGPoFrb0uXhsJpUl/uAJBFsT/Ji/+NeeONcBv3+uvTFfir6aAOAHk3MlsAi2PPn42Wxc0GJgNI\nOgIYKGlwYp1jgN8mln03uiV2nqT1y+zvuRL7c73JihWheJp0zjnw4otw773NP6ZWO+II2HNPOOig\n7LZ55JHw6qvw9tvZbbOvePLJUHNZtgyeeAIKhca3ecIJ4euFFza+rZzl3ciU6oWQ7NZ1ClCQ9ACw\nL6FheHf1BqRhwE7AtNh7TjezHYAPAEOAYq0nzf56hwULYMMNW30UoQdXo2dl9Xr7bXjnnTBGJqmv\ndgC45pqQgNBosT/Ji//123df2GKL2gr81XRQB4D+OW//WWBk7HkXsCS+gpk9z5ormQHAZDN7NbbK\n0cAfzGxV7D1Lo6/vSLoM+Fpsf1tW2l/R1KlTV39fKBQoZHF20UzTpsGbb4bupSNHVl8/LwsWwLvv\nVl8vDzNnhl+2TTYp/fo3vxlGT69cGQZp9gUXXgjjx2dT7E8qFv8PL3VH25X14otw2WXZd/8+91zY\nfvvwO7jddtluO9Ld3U13d3djG6m1iFPLA1iPNYX/DQi3xnZIrDOENeN1vgtMTbx+N7B/Ytmw6KuA\n84H/ip5/jDWF/z3pzYX/Y481A7OrrmrtcfTvbzZ0aGv2fd55ZhttVHmdvtYBYMAAs+9/P59tH3KI\n2fjx+Wy7t3rzzfB7+sor+Wy/yR0AaLfCv4WrjxOBm4HHgKvMbK6kMyUdGq1WAB6XNA8YCpxVfL+k\nUUCXmd2e2PSVkh4CHiI0Ut+N9ncjsFDSE8DPgS/l9uFabc6c8PWBB1p3DG+8Ea5i/v731uz/4Ydh\ns80qr9OXOgA8/HD4N/niF/PZ/oEHhq6zLr3774f11oONNspn+x3QAcBH/Heq4cPDZfjBB8MNN7Tm\nGKZPh498JPwHf/XVkI/VTB/8ILznPeE4yulLCQDHHRd+Fs88k8/2feR/7c47D77zHXj55Xy23+QE\nAB/x35csXx7ux7byzPLee2HjjUMsxl//2vz9L14MY8dWXqcvdQCYNg0+9rH8tu/F/9o9/HA+9bGi\nDugA4I1MJ1q5MvSsOvTQME6kVR55JPwCDR4Md93V/P0XI/6r6QsJAC+/DC+8AF/7WvV1G+Ej/2sz\nf37+HXPaPAHAG5lONGNGuM97wAFhnEirPPFECGDs6oKHHmr+/osR/9X0hSkAfvzjcN8/p15Gq+28\nc98ce1Sv554LGWV5avMpALyR6UR33BG67e61Vxgn0qoBckuWhF+gsWNDg9NMyYj/anp7B4Crrw41\nqrx58b82f/tbuqvtRrVxBwBvZDrR7Nkhvn2TTcIVzcyZrTmO5cth111h4sRwq6aZ7r47FP3Txqb0\n5gSAnh6YNw++1ITOlD7yvzZvvpnuartRbZwA4I1MJ5o/PxT9IfToasUfzp6e8Av0wQ/CfvuFPzzN\nlIz4r2boUBg3Dk5bJwi88/3+9yDlW/Qv8uJ/eosWhavtMWPy31cbdwDwRqYTPf98uHqAME7k4Yeb\nfwzFWyZbbRWOpacnv66zpZSK+K/mW9+CO+/sfR0AfvGL0IMuqzDMarz4n86MGaEW2Kx/lzbtAOCN\nTCdasSLkIUE4s2zFf6q77gr98/v1C4/3vQ8ajZ+oxcKFYcKnWvTWDgD33hvic5rFi//pzJpV29V2\no9q0A4A3Mp1m2TJYtSqk7EK4FF+8uPJ78vDAA/D+9695vummcM89zdt/uYj/anpbB4C8R/mX0qzi\n/4oVoXNJI4833sj/OMt57LFQO22mNuwA4I1Mp7nttlDw7h9lm+62WyjAN9u8eSFZtmj06PBL1Szl\nIv6r6W0dAH74w9CFvJlpC80o/i9ZEq4CttiisUeeAyGrefpp2Hbb5u6zDTsAeCPTaWbMgCFD1jzf\na6/WnK0tWrT2L9C4ceGXqhkqRfxX09s6AOQ9yr+UZhT/Tz01xAGFeMn6HosXw+uvty4lfOnSUCtr\npjbsAOCNTKd59NGQH1W0ww7hF6qZRXcIt+3it6v23DNcITRDtYj/anpLB4BmjfIvJe/i///9X+Nd\nsru6wv+TBx/M5phqVe/VdqParAOANzKdZuHCtQcg9usXitl3393c43j1Vdh99zXPC4XQpbkZ94Lv\nvbex20O9pQNAs0b5l5Jn8f+KK8KVahZXm4MGNbdDStHKleEKaq+9mr/vNusA4I1Mp1m2bN2zo002\naW7kfzHiv9j5AMLVlRR61OQtTcR/Nb2hA0CzRvmXkmfx/6yzQmRS/wzmVBw+vDn/J5Pyjvivpo06\nAHgj00l6esI95gMPXHv5iBFr5pdphnvuCX8AktM/DxrUnDTmBQsaDx3s9A4AzRzlX0pexf8lS+Dx\nx+H7389me9tuG35Ozdbo1Xaj2qgDgDcynWTOnHC1kLw9svXWzc2Tuvfe0KAkDRvWnCuqNBH/1XR6\nB4BmjvIvJa/i/6mnhquPrPK+JkwIIZXNlnfEfzVt1AHAG5lO0t0NAwasu3znnZsb+V+M+E9q1llj\n2oj/ajq5A8BFFzV3lH8peRT/syj4x+2zT2tmbm1GxH81bdIBwBuZTnL//bD55usu/8AHmhv5X4z4\nT9plF3j22fz3nzbiv5pO7gBwzz3NHeVfStbF/ywL/kX77hvqh82eEqMZEf/VtEkHAG9kOsmcOaWj\nVJod+V+M+E/ae+/8zxprjfivphM7ALRilH8pWRf/syz4F224Ybit1+yZW5sV8V9NG3QAyL2RkXSw\npHmS5kta5xRF0khJt0h6SNJ0SSOi5QVJD0qaFX19U9Jhiff+RNKrsedbRtuYJWm2pI/m/fmaavHi\ncLWQ1OzI/2LEf1KhEBq7117Lb9+1RvxX04kdAFoxyr+ULIv/WRf841oxc2uzIv6raYMOALk2MpL6\nARcABwHjgCmSkhXbHwC/NLNdgG8D5wCYWbeZ7WpmuwEHAq8DN8e2PRHYGLDYtr4J/C56zxSg9V0r\nsrR8+drdhuOaFfkfj/gvdQz9+4dJ1fJSa8R/NZ3YAaAVo/xLybL4n3XBP27LLZs7c2szI/6raYMO\nAHlfyewOLDCzRWb2DnAVcHhinR2B6RAalhKvAxwJ3GRmK2F143UucAqg2Ho9QLFj+iZAC7qV5GTl\nynDGeMABpV9vVuR/POK/lMGDQzE9L/VE/FfTSR0AWjnKv5Ssiv9ZF/zjxo6FJ5/MZ9ulNDviv5oW\ndwDI+6ewBRCPCH42WhY3G5gMIOkIYKCk5KnqMcBvY89PBK41s2SXqjOBf5G0GLgBOKmxw28jM2aE\nW2Lx5OO4kSNDj5a83Xnnmoj/Urq68j1rrCfiv5pO6gDQylH+pWRR/M+j4B83aVJzZ25tdsR/NS3u\nAJBhha0klVhmieenABdIOg74K+HqY3WinaRhwE7AtOj5cOAoYP8S254CXGZm50vaE7iCcJtuHVOn\nTl39faFQoFAopPk8rXPHHbDxxuVfHzMGbrgh/+OYNat8Q1c8jjyzopYuDY1C1iZPhksvhW9/O/tt\nZ6mVo/xLOfBAiP0u1SWPgn9codDcmVtbEfFfzckn13US1d3dTXejsTxmltsD2BP4c+z56cBpFdYf\nADyTWPZl4Gex5x8DlgBPAQuBVcD86LVHgS1i6z4JbFpiP9ZxPv5xs513Lv/6RReZDRiQ/3H8wz+Y\n7b57+dd/8AOzjTfOb//rr2/2pz9lv91HHw3Zva++mv22s7Jqldl665n98Y+tPpI1Fi0KP7e33qrv\n/c89ZyaZPfhgtscVt2pVOMann85vH3E77GD2yU82Z19prVoVHg2K/nbW1A7kfbtsJrCtpFGSNiDc\n9ro+voKkIZKKVzzfAC5NbGMKsVtlZnajmY0ws63NbCvgDTOLJrxnEfDhaLs7AO8xs5cy/1StMH8+\nbL99+debFfmfjPhP2m+//M4aG4n4r2bcuNBx4YILst92Vv73f1s7yr+URov/eRb8i4ozt06fnt8+\n4loR8V9NcQbbVuw6z42b2SpC/eRm4DHgKjObK+lMSYdGqxWAxyXNA4YCZxXfL2kU0GVmt1faTez7\nrwOflzQbuBI4NrMP02rPPw8TJ5Z/vVmR/8mI/6SJE0MPtDwGZTYa8V/NXnvBb39bfb1W+cUvWj/K\nv5Rhw+q/VZtnwT9u6FC477789wOti/hvU3nXZDCzPwNjEsvOiH1/DXBNmfcuArassv2NYt/PBfZp\n5Hjb1ooVYfRyOfHI/zzjLJIR/6WOo3jW+OlPZ7vvvEMHjz8ejjkmNJLt9occwij/M86ovl6zjR9f\n3x/wvAv+caNHh7mY8tbKiP821Ya/SW4dy5bBqlWV/7hD/pH/pSL+S9l00/AHMWtZRPxX8olPhKvB\nP/4xv33Uq11G+ZdS78j/vAv+cTvvHG715q3VEf9tyBuZTnDbbWGU+wYbVF4v78j/chH/SaNHhx42\nWcsi4r+Sfv1CXM3//E9++6hXu4zyL6Wekf95jvAvZY89mjNza6sj/tuQNzKdYMYMGDKk+np5R/6X\ni/hPGjcOnn46+/1nEfFfzZQp4efdbm6+ub0K/nH1FP9POSX/gn9cobDmVlaeWh3x34aqNjKS2qyb\nRB/06KNh5slq8o78Lxfxn7TnnvmcNWYV8V/JCSeEs/K5c/PdTy1efjl0/GiXUf6l1Fr8/8Mfmjvh\nWldXuFLNcwwXtEfEf5tJcyXzM0n3SfqSpJy69biKFi5Mlzqcd+R/uYj/pEIh5JtlnfyaVcR/JRtt\nFG47tsFkT6u12yj/Umop/jez4B83aFCYkylP7RDx32aqNjJmtg/wT4ReXvdL+o2kj+R+ZG6NZcvS\ndYnMO/K/XMR/0qhRYTxHlnOrZx3xX8lHP5r9jI+NaLdR/qXUUvxvZsE/bvjwbP9PltIuEf9tJFVN\nxswWEBKOTyPEufw4iu8/Is+Dc4SrgddfD7/E1eQd+V8u4r+UQYOyncMj64j/Sv7938MZaZ5TFqTV\n0xNmG23mraV6pC3+N7vgH9eMmVvbJeK/jaSpyYyXdD4wlxC5/49mtkP0/fk5H5+bMydcFaS9VZJX\n5H+liP9Shg3Ltjt11hH/lbTT6P92HOVfStrif7ML/nETJoSTh7y0U8R/G0lzWngBMAvYxcxOMLNZ\nAGa2hHB14/LU3Q0DBqRfP6/I/2oR/0lZnzXmEfFfSbuM/m/XUf6lpCn+N7vgH7fPPvnO3NpuEf9t\nIs1P42PAb8zsTQhzuUjaEMDMfp3nwTnC4K7NN0+/fl6R/9Ui/pN22SXbaJk8Iv4rOf740LC1cNpa\nIIxN+tSnWnsMaVUr/req4F+0776hC3NenWPaLeK/TaT5i3EL8L7Y8w2jZa4Z5syp7Y/rmDH55IZV\ni/hP2nvvbM8aly6tnJmWtXYY/d/Oo/xLqVb8b1XBv2jDDcMtvSxrhXHtGPHfBtI0Mu81s9UV0Oj7\nKkO+XWYWLw5XBWnttlso0Gdt3jzYIjnfXAWFQjhrzap43uzQwXYY/X/++e07yr+USsX/Vhb84wYP\nhrvuymfbTz9dOaG8j0rTyLwuabfiE0kTgTfzOyS3luXLq2eFxeUV+V8t4j9p4MBwxnrHHY3vO8+I\n/0paPfp/2rT2L/jHVSr+t7LgH7fllvnN3NqOEf9tIE0j81Xg95LukHQH8DtCfL/L28qV4Q/sAQek\nf09ekf/VIv5LGTw41HIalXfEfzmtHP3fCaP8SylX/G9lwT9u7Fh48sl8tu0R/yWlGYw5ExgLfBH4\nErCDmeUY9etWmzEjjHuppRYSj/zPUrWI/1K6urI5a2xV6GArR/93wij/UkoV/3/1q9YW/OMmTYIX\nXsh+ux7xX1bavnZjgB2BXYEpkjKeKMSVdMcdsPHGtb8v68j/tBH/SWPGhCiaRuUd8V9Jq0b/d8Io\n/1JKFf/PPru1Bf+4QiGfmVs94r+sNIMxzwB+Ej0OAL4PHJbzcTmA2bNrK7YXjRiRbdT+3Xeni/hP\nyuqsMe+I/0paMfq/U0b5l5Is/rdLwb9o/PhwOznruWU84r+sNFcyRwIfAl4ws88AuwB1nF67ms2f\nD9tvX/v7tt4626j9++5LF/GftN9+2Zw1NiPiv5xWjP7vlFH+pSSL/+1S8C+Kz9yaJY/4LytNI/Om\nmfUA70raCFhGlSmRXUaefx4mTqz9fVlH/qeN+E+aODGclTc6bqcZEf+V7L13c0f/d9Io/1Lixf92\nKfjHDR2affSSR/yXleZ/8f1RxP9FwAOEiJnUVWVJB0dhmvMlrVP5kzRS0i2SHpI0XdKIaHlB0oOS\nZkVf35R0WOK9P5H0amLZ0ZIek/SIpCvSHmdbWrEijFKuVdaR/2kj/pOyOmtsRsR/JV/4QnNH/3fS\nKP9SisX/dir4x+Uxc6tH/JdnZmUfgIAtY89HA+MrvSfx/n7AE8AoYH1gNjA2sc7VwD9H3xeAX5XY\nzmDgJcLA0OKyicCvgBWxZdsSGsKNouebljkua3tLl5qB2Vtv1f7ev/+9/veWssUWZl/9an3v3XJL\nsy9+sf59L1oUPsuqVfVvo1GrVpmtt57Ztdfmv69HHjGTzF59Nf995eW888wGDTIbO9bsIx9p9dGs\n68QTw//LLG24odnFF2e7zTYU/e1M9fe/+Kh4JRNt9MbY86fNrJb0xd2BBWa2yMzeAa4CDk+ssyMw\nPdp+d4nXIdSFbjKzlRDy04BzgVMIDWHR54GfmtmKaHsv1XCs7eW220K0/QYb1P7erCP/a4n4T2r0\nrLGZEf/lNHP0/3nnddYo/1KKxf92KvjH7bFH9jO3esR/WWl+c2dJqneE0RbA4tjzZ6NlcbOByQDR\n/DQDJSVT5o4B4jfFTwSuNbNk4WF7YIykOyXNkHRQncfdejNmwJAh9b8/q8j/WiP+k8aNa6wTQjMj\n/itp1uj/ThvlX0qx+N9OBf+4QmHNuJYseMR/RWk6ru8B/JOkRcDrhCsHM7PxKd6rEsss8fwU4AJJ\nxwF/BZ4DVv/rSxoG7ARMi54PB44iTJ6W1J9wy2w/YCRwh6RxxSubuKlTp67+vlAoUCgUUnycJnr0\n0TDDZL022yybgZDF0dFpI/6T9twTLr+8/v03O+K/nBNOgP/4jzD6P69779Onhy7fnTbKv5SDDoIj\n2nROw66ucHX6wAPhqqZRvTjiv7u7m+4Gp6xO08g0cjXwLOGPfVEXsCS+gpk9z5ormQHAZDOLF/OP\nBv5gZqui57sC2wBPSBKwoaT5ZrZ9tL+7LfSGe1rS48B2hDrNWuKNTFtauDDdbJjljBwZxpc0asaM\n2iL+kwqFcCXU01PfNhYubI+Canz0/0UXZb/9nh445hg4+ODOG+VfSivTq9MoztyaRSPTiyP+kyfg\nZ555Zs3bSPNbb2UeacwEtpU0StIGhNte18dXkDQkaiwAvgFcmtjGFGK3yszsRjMbYWZbm9lWwBtR\nAwNwLWHGTiRtSmhgnkp5rO1l2bLGcpCyivyvNeI/adSoMOaj3rnVmx3xX0meo/+/9S145ZUw0t/l\nb/jw+v9PJnnEf0VpGpk/ATdEX28l/NFO9ZsWXX2cCNwMPAZcZWZzJZ0p6dBotQLwuKR5wFDgrOL7\nJY0Cuszs9kq7ie1vGvA3SY9Fx/p1M8txKryc9PTA6683diWTVeR/rRH/pRTPGuvRTqGDeY3+X748\nFMi/853OLvh3kixnbvWI/4qq3i4zs7VOI6PY/9Sjq8zsz4Tss/iyM2LfXwNcU+a9i6gy8NPMNko8\n/xrQ2Te158wJZ/+N3DbJKvJ/0aL6BoTGDRtWX5ZaqyL+y4mP/j/99Oy2+4lPhDPrU0/NbpuusgkT\nshuQ6RH/FdV8k9zMZhE6A7i8dHfDgAGNbSOryP96Iv6T6j1rbFXEfyVZj/6fPj0EoV5T8jzL5WWf\nfbKbubWdrrbbUNUrGUknx572A3YjUbx3Gbv/fth888a2EY/8byTuop6I/6RddgmfqVbtGDr4hS+E\nAn29HRni4sV+/yPVXPvuG7owr1jRWHKyR/xXlea3ZFDs8R5CbabUgEmXlTlzQshloxqN/K834j9p\n773rO2tsZcR/OZ/4RLhCzKL3lBf7W2fDDcNYnnprhUUe8V9VmppM7X3WXGMWL4b9Sw0DqlGjkf/1\nRvwnFQqhtvLaa7VdmbQy4r+c+Oj/wxs41yoW+886q/2u1vqKwYPhrrvg0EOrr1tOO15tt5k088n8\nJQrILD4fLGlavofVxy1f3vjVAzQe+V9vxH/SwIGhsbrjjtre18qI/0qyGP3vxf7W23LLxgcse8R/\nVWlul20144kvAAAgAElEQVRmZi8Xn0Rdgv2nmpeVK0OvqgMOaHxbjUb+1xvxX8rgwXDnnbW9p9UR\n/+WccEKoVc2dW9/7b73Vi/3tYOzYxmdu9Yj/qtI0Mqskrf4pRmNX0g7GdLW6665wj7eRAZBFjUb+\n1xvxX0pXV+1nja2O+C8nPvq/Vj094UrIi/2tN2lS4/MuecR/VWliZf4fcKek4oDI/YAv5HdIfdyd\nd8LGGU08utdeoRby9tv1pTkvWZLdPPNjxoTppNN65plQYN9xx2z2n7V6R/97sb99FAqNz9z6t7+1\n59V2G6l6JRMNptwN+B1h7peJ0ch6l4fZsxsfYV/UaOR/IxH/SZMmhZk+02qHiP9K6hn97yP728v4\n8eFEZtGi+rfhEf9VpSn8fwJ4x8xuMLM/EqZh/nj+h9ZHzZ8P229ffb206o38bzTiP2m//Wo7a2yX\niP9y4qP/0/Jif3tpdOZWj/hPJc1p4hlm9krxSdQJ4IwK67tGPP984zEucfVG/jca8Z80cWJouNKG\ndrZLxH8ltYz+92J/exo6tP54mV4c8Z+lND+dUuukqeW4erzyShiNnJV6I/8bjfhPqvWsceHCbAak\n5ukLXwiNYU9P5fW82N++Gpm5tRdH/GcpzV+Q+yX9UNI2kraWdD4l5mdxGXjhhfAHqdEYl7h6I/8b\njfgvZdNN0581tlPEfzlpR/97sb997bxz/TUZj/hPJU0jcxLwNqHw/3tgJXBCngfVZ91+eyh219MT\nrJx6I/+ziPhPGj06zPiZRieEDsZH/5fz0kte7G9ne+wBL75Y33s94j+VNLEyrwMZ5pq7smbMgCFD\nst1mvZH/WUT8J40bBzfeWH29dov4r2TKFDj77PKvH3GEF/vbWaGwJuSyf41VAI/4TyVN77LNJJ0r\n6UZJ04uPZhxcn/Poo9mPHq438j+LiP+k3XdPd9bYjhH/5VQa/X/rrWHckxf721dXV/i/Vk+QbCdc\nbbeBNLfLrgTmAVsBZwJPE6ZVdll76qlwtp+leOR/LbKI+E868MDQLbpaobyTQgfLjf73Yn/nqGfm\nVo/4Ty1NIzPEzC4hjJW53cw+CzQwL7Ar68UX8/mDtMkmtc3n8tpr2UT8J40aFWb8rDbyvx0j/isp\nNfr/m9/0Yn+nGD48dHSphUf8p5amkXkn+vq8pEMk7Qpk3O3I0dMDr78ezvazNmJE6Gqb1r33ZhPx\nX8qgQWHmz0raMeK/kuTo/5degnPP9WJ/p6hn5tZOutpusTSNzHclbQx8Dfg6cDHw72l3IOlgSfMk\nzZd0WonXR0q6RdJDUb1nRLS8IOlBSbOir29KOizx3p9IWmcYuaQjJfVI2i3tcbbcnDnhLH+77bLf\ndq2R/1lF/JcybFj1+9/tGvFfTnL0vxf7O8uECeEkoRYe8Z9amuyyG8zsFTN71MwOMLOJZnZ9mo1L\n6gdcABwEjAOmSEr+9fgB8Esz2wX4NnBOtN9uM9vVzHYj3J57Hbg5tu2JwMYkEqElDSR0u74nzTG2\nje5uGDAgn23XGvmfZcR/0jbbVD9rbNeI/0qKo/+92N959tmn9plbPeI/tbzzEHYHFpjZIjN7B7iK\ndadu3hGYDqFhKfE6wJHATWa2ElY3XucCp5RY9zvA94C3svgATTNzJmy+eT7brjXyP8uI/6QJE6oP\nDm3XiP9KiqP/vdjfefbdN9Qga/kd8Yj/1PJuZLYAFseePxsti5sNTAaQdAQwUFIyq+EYIB4SdSJw\nrZktBVRcKGkC0GVmKQZjtJm5c/OLUYlH/qexZEl+v0B77135rLHdI/7LKY7+92J/59lwQ1h//dp6\nmHnEf2p5Z5CpxLLkhGenABdIOg74K/Ac8O7qDUjDgJ2AadHz4cBRwP5r7UgScD5wbJX9AzB16tTV\n3xcKBQqFQpWPkrPFi2H//auvV4945H+aVOUsI/6TCoXQ4L32WunCabtH/JfTrx989rNhBLkXhDvP\n4MFhwsBDD023fh+J+O/u7qa7WkedKmRWeZJLSe8hXGmMJtYomdm3q25c2hOYamYHR89PD2+175VZ\nfwAw18ziM3F+GdjRzP4tev4xQueDlYRGZCTwJDAp+vpqtHwY8DfgMDObldiPVfvcTfee98BvfgOT\nJ+ez/U02gf/8Tzj55Mrr9fSEBumJJ0L9JA/rrw/XXx+6/iadeir8+te1zT3jXKMmTQp1yDSJFIsW\nhdvJq1Z13slQgyRhZmVP3ktJ8xO6jlAneZdQfC8+0pgJbCtplKQNCLe91uo0IGlIdBUC8A3g0sQ2\nphC7VWZmN5rZCDPb2sy2At4ws+3NbIWZbRZbfg/wj8kGpi2tXBluZR1wQH77SBv5n3XEfymDB4fi\neCmdEPHvep+xY8OJVRoe8V+TNLfLuopXIrUys1WSTiT0CusHXGJmcyWdCcw0sxuAAnC2pB7C7bLV\n4ZuSRkX7v33dra/ZTYXlNbW4LXPXXeHqIevU47i0kf9ZR/yX0tVVvsFbuNALqq75Jk2qnqZd5BH/\nNUnTyMyQtLOZPVLPDqLpm8cklp0R+/4aoGR/TzNbBGxZZfslh9yaWeekEtx5J2y8cb77GDMGbrih\n+np5RPyXOpZyo/6XLoWjj853/84lFQrpZ271iP+apDld3Qd4QNLjkh6W9Iikh/M+sD5l9uzsY/WT\n0kb+5xHxnzRpUvmai4cOulYYPz70Dly4sPq6HvFfkzRXMiWqsy5T8+fnf4sobeR/HhH/SfvtV/qs\nsZMi/l3vUpy5tbu7ej3SI/5rkmbE/yJgE+Afo8cm0TKXleefz6/LcFHayP88Iv6Tdt019GJLDsrs\npIh/1/sMHZpu5la/2q5JmvlkvkKI+x8aPa6QdFLeB9anvPJKfmNkitJG/ucR8Z/Uv384a5yemJbI\nQwddK40eHeotlXjEf83S1GQ+B+xhZv9pZv8J7Al8Pt/D6kNeeCGc1ef9hx2qR/7nFfFfyqabrnvW\n2GkR/6532Xnn6kGyHvFfszSNjIBVseer6JSuwZ3g9tvDQMwNNsh/X9Ui//OM+E8aPTrMBBrXaRH/\nrnfZY48wTUMlfrVdszSNzGXAvZKmSppKGOR4Sa5H1ZfMmAFDhjRnX9Ui//OM+E8aN27dY+m0iH/X\nuxQKa26HleMR/zVLU/j/IfAZYDnwd+AzZvbfeR9Yn/Hoo807e68W+Z9nxH/S7ruHmUDjOjHi3/Ue\nXV2hdllpviOP+K9Z2UZG0kbR1/cDTwNXAL8GFkXLXBaeeiqc1TdDtcj/PCP+kw48MIQM9vSsWdaJ\nEf+udxk0qHIas0f816zSlcxvoq8PAPfHHsXnLgsvvti87pDVIv/zjPhPGjUqzARaHPnfqRH/rncZ\nPrzylYxH/NesbCNjZodGX7eKQieLj63MLKeJT/qYnh54/fVwVt8M8cj/UvKM+C9l0KAw+A06N+Lf\n9S7bbguPP17+9T4S8Z+lNONkbk2zzNVhzpxwNr/dds3b58CBcE+Jmal7esIvUJr5ZrIybNias8YH\nHvDQQdd6EyaEW2KlLFoUrrbHjCn9uiupUk3mvVHtZVNJgyW9P3qMBjwdLgvd3TBgQHP3udlmoYdM\nUjMi/pO22SZkpYFH/Lv2sM8+5Wdu9Yj/ulT6aR1PqL+Mjb4WH9cBP83/0PqAmTNh882bu89ykf/N\niPhPmjBhTbTMwoX5TT/tXFr77hu6MJfqIOMR/3WpVJP5UTT519djtZitzGwXM7ugicfYe82d2/w/\nrGPGrJsZBs2J+E/ae+81Z41Ll+afmeZcNRtuGGZuLTXlsEf81yXNOJmfSNpJ0tGSPl18NOPger3F\ni2GXXZq7z3KR/82I+E8qFEJvt9de89BB1z4GDy6d8ecR/3WpGvUv6QzC7JU7AjcSov/vBH6V65H1\nBcuXNycnLK5c5H8zIv6TBg4MMTbTp3vEv2sfW25ZeuZWj/ivS5ob8EcCHwJeMLPPALsAOU/j2Aes\nXBnGqxxwQHP3Wy7yvxkR/6UMHgy/+pVH/Lv2MXZsGJic5FfbdUnTyLxpZj3Au1EKwDKqTInsUrjr\nrjBmpdl1kGLk/113rb18xYrmJEEndXWFEdYeOujaxaRJ68YvecR/3dI0MvdL2gS4iNC7bBZQZVKS\nNSQdLGmepPmSTivx+khJt0h6SNJ0SSOi5QVJD0qaFX19U9Jhiff+RNKrsef/LukxSbMl/UVS+zaG\nd94JG7fognCTTUKhv+i112DVqubfuoPQEeHFFz3i37WPQmHdmVs94r9uaQr/XzKzl83sZ8BHgGOj\n22ZVSeoHXAAcBIwDpkhKxuz+APilme0CfBs4J9pvt5ntama7AQcCrwM3x7Y9kXDbzmLbmgVMNLMJ\nwDXAuWmOsyVmz25+ob0oGfnfzIj/pEmTwlcPHXTtYvz4cEt54cI1yzziv26VBmPulnwA7wf6R9+n\nsTuwwMwWmdk7wFXA4Yl1dgSmQ2hYSrwOoS50k5mtjI6tH6EBOSW+kpndXlyHMCVBi/6KpzB/Pmy/\nfWv2nYz8b2bEf9J++4WvHvHv2kW/fmHMWLwbs0f8163Slcx50eOnwL3ALwi3zO4l/WDMLYDFsefP\nsu4f/tnAZABJRwADJSVHPB0D/Db2/ETgWjNbSvkJ1D4H3JTyOJtvyZLm5oTFJSP/mxnxn1T8GXjo\noGsnQ4euPXOrR/zXrWwXZjM7AEDS/wG7mdkj0fOdgKkpt1+qAbDE81OACyQdB/wVeA5YPWuQpGHA\nTsC06Plw4Chg/7I7lf4ZmFhpnalTp67+vlAoUCgUKn2ObF13HbzyChxzTPP2GZeM/G9mxH9S//7h\n53DEEa3Zv3OljB4dBl8WPfccHF7qJkvv1t3dTXepgak1kFnyb35iBekxMxtXbVmZ9+4JTDWzg6Pn\npwNmZt8rs/4AYK6ZjYwt+zKwo5n9W/T8Y8DFwEpCIzYSeNLMto9e/zDwI2A/M/tbmf1Ytc+dm56e\nMBPmhz8Mv/99a47h5ZdD1+G33grTPnd1wVFHwfnnt+Z4nGs3J50E114bBkxDyBj88Y/hc59r7XG1\nmCTMrNzdo5LS9C57WNLFUW+v/SVdBJRIWCxpJrCtpFGSNiDc9ro+cdBDJBUP+hvApYltTCF2q8zM\nbjSzEcWoG+CNWAOzK/Az4LByDUzLfeUr4Y/7r3/dumNIRv43O+LfuXa3xx7w0ktrnnvEf93SNDKf\nAR4DvgJ8FZgTLavKzFYR6ic3R9u4yszmSjpT0qHRagXgcUnzgKHAWcX3SxoFdJnZ7ZV2E/v++8AA\n4PdRt+dr0xxn0yxZAhdeGK4Y3vve1h5LMfK/FRH/zrW7QmHN2BiP+G9I1dtlvVHLbpdNmhRqMaVS\nkJttu+3Cmdk3vxl6ua1a5RHmzsWtt15IJ3/qKfjsZ8PJWB9Xz+2ysoV/SVeb2dGSHmHdYj1mNr6O\nY+y7rrsuDIB85JFWH0lQjPxvRcS/c51g0KCQRrFsmUf8N6BSQOZXoq+HVljHpdHTA8cdB5Mnw7iq\n/SWaY8wYuOGG1kT8O9cJhg8PM7auWOER/w2o1IX5+ejrouYdTi/VDsX+pN12C8GUrYj4d64TbLst\nPP54+N0d7zdu6lXpdtmrlLhNRug2bGbmIT5pFIv9F17Y+mJ/XDHyvxUR/851ggkTwoDMVas84r8B\nlWbGHGRmG5V4DPIGpgaHHRZiXI4/vtVHsrZi5P/ixT4jpXOl7LNPmLnVI/4bUnXSsiJJQ4HVp+Jm\n9kyF1R20X7E/rhj5/8YbrYn4d67d7btv6MIMHvHfgDQj/g8jZJiNIMwlM4owKr9NKti1a0oX5nYY\n2V/N8OHwwgvw+uutSWB2rt1tsEH4XX733err9gF5jfj/DrAnMD8aYf8hQsKxq6Qdi/1JI0a0LuLf\nuU4weLBH/DcoTSPzThTR0k9SPzO7DZiU83F1tnYa2V/J1lu3LuLfuU6w5ZYe8d+gNDWZlyUNJCQk\nXylpGWECMVdOuxb7k04+2SP2navk9NNDoKyrW5qazADWJB7/E2E2yivbNoAyhVxrMtddB5/4RCj2\nt8vAS+ecy0A9NZmyjYykC4DfmNmMLA6uneTWyHRCsd855+qUdeF/AXCepKclfU+S31epphOK/c45\n10RpbpeNIswDcwxhnMxvCZH98/M/vHzkciWzZEkoEl54YfvXYpxzrg6Z3i4rs4NdCZOKjTez9Wo8\nvraRSyPTTjH+zjmXg0yj/mMbXR84mHAl8yHgduDMuo6wt2rnkf3OOddClQr/HyFMfXwIcB9wFXCt\nmXV89+VMr2S82O+c6yOy7l12G/Ab4BozW57B8bWNTBuZk06CSy6B5cvbe+Clc841KPeaTG+RWSPj\nxX7nXB+SV3ZZQyQdLGmepPmSTivx+khJt0h6SNJ0SSOi5QVJD0qaFX19MwrrjL/3J9G8N8XnG0i6\nStICSXdLGpnrh+uUkf3OOdciuTYykvoBFwAHAeOAKZLGJlb7AfBLM9sF+DZwDoCZdZvZrma2G3Ag\nIcrm5ti2JxLSB+KXJJ8DlpvZdsB/A9/P5YPBmmL/tdfmtgvnnOt0eV/J7A4sMLNFZvYOofPA4Yl1\ndgSmQ2hYSrwOcCRwk5mthNWN17nAKYS4m6LDgcuj7/+X0Bsuez09cNxxMHmyR8c451wFeTcyWwCL\nY8+fjZbFzQYmA0g6AhgoaXBinWMIg0CLTiT0dFtabn9mtooQ7vn+hj5BKT6y3znnUkk9M2adShWI\nkhX3U4ALJB1HSHp+Dlg9Q5CkYcBOwLTo+XDgKGD/FPtTif0BMHXq1NXfFwoFCoVC2Q+xlmKM/4UX\nem8y51yv1t3dTXd3d0PbyLV3maQ9galmdnD0/HTAzOx7ZdYfQJh1c2Rs2ZeBHc3s36LnHwMuZk0y\n9EjgSTPbXtKfgTPM7F5J6wHPm9k6k0E01LvMR/Y75/qoXEb8N2gmsG2Uf/Y84bbXlPgKkoYQivUG\nfIMQWxM3BTi9+MTMbiRMBV18/6tmtn309HrgWOBewtXO9Ew/jY/sd865muRak4nqIicSeoU9RgjW\nnCvpTEmHRqsVgMclzQOGAmcV3x81Tl1mdnul3cS+vwTYVNIC4KvEGqeGebHfOedq5oMx0/KR/c65\nPq4db5f1Dl7sd865uviVTBpe7HfOOb+SyYUX+51zrm5+JVOJx/g759xqbRmQ2dF8ZL9zzjXEb5eV\n48V+55xrmN8uK8eL/c45txYv/GfFi/3OOZcJv5JJ8mK/c86V5IX/LHix3znnMuO3y+K82O+cc5ny\n22VxXux3zrmyvPDfCC/2O+dc5vxKBrzY75xzKXjhv15e7HfOuVz47TIv9jvnXG78dpkX+51zLhUv\n/NfKi/3OOZer3Gsykg6WNE/SfEmnlXh9pKRbJD0kabqkEdHygqQHJc2Kvr4p6bDotYslzY4eV0va\nMFq+ZbSNWdFrHy17YD09cNxxMHkyjBuXz4d3zrk+LtfbZZL6AfOBDwFLgJnAMWY2L7bO1cD1ZnaF\npALwWTP7dGI7g4EFQJeZrZQ00Mxei147D1hqZt+X9HNglpn9XNIOwI1mtlWJ4zI78US45BJYvtxr\nMc45l0I79i7bHVhgZovM7B3gKuDwxDo7AtMBzKy7xOsARwI3mdnKaL1iAyPgfUCxpewBNoq+3wR4\nruyRXXghnH++NzDOOZejvBuZLYDFsefPRsviZgOTASQdAQyMrlzijgF+G18g6VLgeWAM8JNo8ZnA\nv0haDNwAnFT2yLbeGo4/vpbP4pxzrkZ5NzKlLquS9+dOAQqSHgD2JVx9vLt6A9IwYCdg2lobMfss\nMByYC3wyWjwFuMzMtgQOAa4oe2TXXlvL53DOOVeHvHuXPQuMjD3vItRmVjOz51lzJTMAmGxmr8ZW\nORr4g5mtSm7czCyq6XwduBz4HHBQ9No9kt4raVMzeyn53qm///3q0f2FQoFCoVD3h3TOud6ou7ub\n7u7uhraRd+F/PeBxQuH/eeA+YIqZzY2tMwRYHjUY3wXeNbOpsdfvBk43s9tjy7Yxsyejmsz3Ce3N\nqZL+BFxtZpdHhf+/mFlXieOqPjOmc865tbTdOBkzWyXpROBmwq25S8xsrqQzgZlmdgNQAM6W1AP8\nFTih+H5Jowg9yuINjIDLJQ0i3I57CPhi9PLXgYsk/TuhE8CxeX4+55xzlfmIf+ecc6m0Yxdm55xz\nfZg3Ms4553LjjYxzzrnceCPjnHMuN97IOOecy403Ms4553LjjYxzzrnceCPjnHMuN97IOOecy403\nMs4553LjjYxzzrnceCPjnHMuN97IOOecy403Ms4553LjjYxzzrnceCPjnHMuN97IOOecy403Ms45\n53LjjYxzzrnc5N7ISDpY0jxJ8yWdVuL1kZJukfSQpOmSRkTLC5IelDQr+vqmpMOi1y6WNDt6XC1p\nw9j2jpb0mKRHJF2R9+dzzjlXXq6NjKR+wAXAQcA4YIqksYnVfgD80sx2Ab4NnANgZt1mtquZ7QYc\nCLwO3By956tmNsHMJgCLgROj/W0HnAbsZWY7A1/N8/O5oLu7u9WH0Kv4zzM7/rNsvbyvZHYHFpjZ\nIjN7B7gKODyxzo7AdAgNS4nXAY4EbjKzldF6rwFIEvA+wKL1/hX4qZmtiNZ7KdNP40ryX+Rs+c8z\nO/6zbL28G5ktCFcaRc9Gy+JmA5MBJB0BDJQ0OLHOMcBv4wskXQo8D4wBfhIt3h4YI+lOSTMkHZTJ\np3DOOVeXvBsZlVhmieenAAVJDwD7As8B767egDQM2AmYttZGzD4LDAfmAp+MFvcHtgX2Az4FXCxp\no8Y/hnPOubqYWW4PYE/gz7HnpwOnVVh/APBMYtmXgZ9VeM9+wPXR9/8DfDr22i3AxBLvMX/4wx/+\n8Eftj1rbgf7kayawraRRhFtbxwBT4itIGgIst/DX/xvApYltTCE0TvH3bGNmT0Y1mX8E5kUvXRut\n/ytJmwLbAU8lD8rMSl1hOeecy1iut8vMbBWh59fNwGPAVWY2V9KZkg6NVisAj0uaBwwFziq+P2qc\nuszs9tgyAZdLegh4CBhG6JWGmU0D/ibpMeBW4Otm9vc8P6NzzrnyFN0+cs455zLX50b8Vxsc6moj\n6eloIO2Dku5r9fF0EkmXSFoq6eHYssGSbpb0uKRpkjZu5TF2kjI/zzMkPRsN6p4l6eBWHmOnkNQV\nDY6fEw1s/3K0vOb/n32qkUk5ONTVpgcoRANnd2/1wXSYywj/F+NOB24xszGE8WPfaPpRda5SP0+A\nH5rZbtHjz80+qA71LnCyme0I7AWcEP2trPn/Z59qZEg3ONTVRvS9/0eZMLM7gWTN8HDg8uj7y4GP\nN/WgOliZnyeUHkrhKjCzF8xsdvT9a4ShIl3U8f+zr/1xSDM41NXGgGmSZkr6fKsPphcYamZLIfyi\nA5u1+Hh6gxOinMOL/fZj7SSNBiYA9wCb1/r/s681MmkGh7ra7G1mk4CPEX6Z92n1ATkXcyGwTZRz\n+ALwwxYfT0eRNBD4X+Ar0RVNzX8v+1oj8ywwMva8C1jSomPpFaKzGczsReAPhFuSrn5LJW0Oq9Mu\nlrX4eDqamb1oa7rQXgR8oJXH00kk9Sc0ML82s+uixTX//+xrjczqwaGSNiAMDr2+xcfUsSRtGJ3p\nIGkA8A/Ao609qo4j1r7Cvh44Lvr+WOC65BtcRWv9PKM/hEVH4P8/a3EpMMfMfhRbVvP/zz43Tibq\nwvgjQgN7iZmd0+JD6liStiJcvRghN+5K/3mmJ+k3hMHIQ4ClwBmE1IrfA1sCzwBHmdnLrTrGTlLm\n53kAoZ7QAzwNHF+sKbjyJH0Q+CvwCGsiZf4DuA+4mhr+f/a5RsY551zz9LXbZc4555rIGxnnnHO5\n8UbGOedcbryRcc45lxtvZJxzzuXGGxnnnHO58UbG9WqSeiSdG3v+NUn/mdG2L5N0RBbbqrKfI6PI\n9Vvz3ldiv8dK+kkz9+l6H29kXG/3FnCEpPe3+kDiomkn0voc8K9m9qG8jqcCH0jnGuKNjOvt3gV+\nAZycfCF5JSLp1ejr/pK6JV0r6QlJZ0v6lKR7ownatopt5iNRAvU8SYdE7+8n6fvR+rOL6dTRdv8q\n6TpgTonjmSLp4ehxdrTsW8A+wCWSvlfiPV+XdF+0nzOiZaMkzZV0RXQFdLWk90avfSiavOuhKJV4\n/Wj5ByTdFW3nnigmCGALSTdFk1R9L/b5LouO8yFJX6nx38T1If1bfQDO5cyAnwKPlPojXWLdovHA\nWOBl4CngIjPbI5oh8CTWNFqjzOwDkrYFbpO0DSHT6eVo/Q2AuyTdHK2/KzDOzJ6J71jScOCc6PWX\ngb9IOszMviPpQMIEUg8m3vMRYDsz212SgOujFOzFwBjgM2Z2j6RLgC9J+ilhYq8DzOxJSZcDX5T0\nP4S5lY4ys1lRHt3KaDe7EGJZ3gEel/RjYHNgCzMbHx3HRlV+rq4P8ysZ1+tFEeWXA7Wccc80s2Vm\n9jbwJFBsJB4BRsfWuzraxxPRemMJQaGflvQgcC/wfmC7aP37kg1M5APAbWa23Mx6gCuB/WKvl5qm\n4h8IV1KzgFmEhqW4n2fM7J7o+ysIV0NjgKfM7Mlo+eXRPsYAS8xsVvRZXjOzVdE6t0bP3yJcfY0i\nNLpbSfqRpIOAV0scm3OAX8m4vuNHhD/El8WWvcvaJ1obxL5/K/Z9T+x5D2v/3sSvfhQ9F3CSmf0l\nfgCS9gdeL3N8yTTmNAScbWYXJfYzqsS6xeMqtY9K+43/HFYB/c3sZUm7EKY6Ph44mlA3cm4dfiXj\nejsBmNnfCVcd8T+GTwOTACR9HFi/ju0fpWAbYCvgcWAa4fZU/2jb20nasMp27gX2k/R+SesBU4Du\nKu+ZBny2WD+RNELSptFrIyXtEX0/BbgDmAeMkrR1tPxfon3MA4ZLmhhtZ2B0DCVJGgKsZ2Z/AL5F\nuMXnXEl+JeN6u/iVxnnACbFlFwHXRbe1plH+KqNSD6tnCPHngwgx8m9LuphwS21WVCtZRpW50M3s\nBaaHRnYAAACiSURBVEnfYE3D8iczu6HS/s3sL5LGAneH3fAq8M+Eq63HCTOVXgY8BvzMzN6S9Bng\nf6NGZCbwczN7R9IngQskvQ94A/hwhZ/DFsBlUQ85A06v9Nlc3+ZR/871MtHtshvMbOdWH4tzfrvM\nud7Jzx5dW/ArGeecc7nxKxnnnHO58UbGOedcbryRcc45lxtvZJxzzuXGGxnnnHO58UbGOedcbv4/\nqaUXIllZ53MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0997545fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('final')\n",
    "plt.xlabel('Number of epochs')\n",
    "plt.ylabel('Validation accuracy')\n",
    "plt.plot(final['epoch'],final['val_acc'],color='red')\n",
    "plt.savefig('plots/final')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
